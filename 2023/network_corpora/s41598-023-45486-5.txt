introduction many application area faced significant challenge result missing data example weather traffic missing data data gathering process due sensor failure network failure significant impact output downstream operation many real-world setting incomplete data must processed result several study spatiotemporal data filling method statistical way fill machine learning filling method deep learning filling method arisen study effective spatiotemporal approach using deep learning reconstruct missing part signal produced better filling result rise graph neural network also facilitated development approach imputation utilize spatiotemporal correlation andrea cini proposed grin bivariate graph rnn rebuild missing data different channel multivariate time series learning spatiotemporal representation message passing however case imputation approach node attribute fluctuate time rather constant one level example air quality collection network air quality given area depends prior air quality area also air quality index nearby area throughout previous time also take time air travel one area another true traffic flow transport sector result capturing spatial correlation node time harmonising temporal spatial continuity emerged significant challenge field data complementation zonghan proposed traversenet address issue employ attention technique pick key neighborhood information deal dynamic spatiotemporal relationship also several graph neural network parse graph using attention process handle traffic flow prediction problem example spatio-temporal graph convolutional network attention astgcn model utilized new direction building update surrounding node fill missing spatiotemporal data using attention method however order capture underlying spatial relationship numerous similar study mapped deeper graph topology creating various adjacency matrix method fully exploit dynamic character spatiotemporal data spatial information change time making difficult capture hidden spatial connection therefore construction dynamic adjacency matrix becomes good way capture spatiotemporal feature example aoyu liu yaying zhang presented stidgcn interactive dynamic graph convolution structure formed merging adaptive learnable adjacency matrix summary paper proposes adgcn dynamic graph attention reconstruction model implemented unified spatiotemporal message passing layer model first attention mechanism construct special messaging layer assigns node moment weight value corresponding influence weight used connect nearby node central node aggregating neighboring node state information update graph reconstruct spatiotemporal deficiency graph model additionally employ dynamic adaptive adjacency matrix learn time-varying correlation node adjacency matrix containing static distance graph convolution gating main contribution paper follows paper attention-based message passing dynamic graph convolution network adgcn proposed message passing layer architecture traverse message node time unifying continuity time space paper present dynamic graph convolution module model adgcn dynamic graph generated fusing dynamic adaptive adjacency matrix static distance adjacency matrix also gating pas information learn spatial correlation node time imputation extensive experiment conducted four real data set two domain experimental result show model adgcn proposed paper advanced performance compared baseline model rest paper structured follows section related work describes related work area data imputation proposed spatiotemporal reconstruction model adgcn described detail section method experimental procedure result described section experiment finally conclusion drawn summary section conclusion related work filling spatiotemporal data large literature exists filling missing value spatiotemporal data includes simple statistical method look overall characteristic data similarity time series fill missing value example include simple mean fill mean chain multiple interpolation azu mouse etc also method consider spatial information filling matrix factorisation cichocki phan etc however field machine learning filling spatiotemporal data viewed prediction task fill missing value predicting missing position data among several variant supervised algorithm prediction imputation including k-nearest neighbor algorithm knn troyanskaya beretta santaniello vector autoregressive algorithm var others algorithm necessarily work well compared simple statistic none fully account spatiotemporal property spatiotemporal data prediction must utilized globally fill gap current advanced spatiotemporal data filling method employ deep learning algorithm among recurrent neural network rnn variant based recursive neural network able achieve better result complementation task cao proposed brit model rnn-based bidirectional gru gating structure multivariate time series imputation take account correlation different channel perform spatial imputation furthermore miao proposed rgain generative adversarial model based bidirectional recurrent neural network encoder-decoder imputes missing input using bidirectional rnn also method use attention mechanism focus time-series relationship completeness wenjie others used self-attention based diagonal masking explicitly capture temporal dependency feature correlation time step graph neural network graph neural network gnns always unique advantage processing spatiotemporal data graph structure gnn efficiently gather spatiotemporal information update graph employing graph adjacency matrix graph convolution operation fuse information neighboring node standard graph neural network considers static spatial information example graphsage hamilton ying leskovec defines fixed neighbor aggregate node neighborhood attribute proposed graph-wave network extended one-dimensional convolution learn static graph structure input spatial dependency spatiotemporal feature present spatiotemporal graph neural network stgnn handle data efficiently weiguo zhu proposed corrstn graphical model traffic flow prediction based spatiotemporal correlation information attention-based mechanism stgnn model time space separately extracting time–space dependency chuanpan zheng proposed gman capture spatial correlation temporal correlation using multiple spatiotemporal attention module wei shao proposed new dynamic multi-graph fusion model fuse multi-graph information modeling intra-graph inter-graph node interaction via spatial graph attention technique research work data filling using graph structure indro spinelli proposed graph convolutional network fused generative adversarial network fill missing data emanuele rossi jiaxuan used graph representation learning deal missing data method architecture adgcn model proposed paper shown fig consists two main part unified spatiotemporal messaging layer constructed using attention mechanism dynamic graph convolution method using dynamic adjacency matrix conjunction static adjacency matrix gating pas information detailed step two section described separately figure adgcn model architecture full size image architecture full model implementation shown fig together vector dimension model input output represents batch size represents number channel dim represents hidden layer dimension represents sensor spatial dimension represents temporal dimension spatiotemporal dimension fuse temporal spatial dimension s=n\times unified spatiotemporal messaging layer dynamic graph convolution filling method gating two key component constitute model figure adgcn model architecture full size image first raw data input unified spatiotemporal messaging layer significant module spatiotemporal attention module fig firstly map data using spatiotemporal embedding extract spatiotemporal feature order unify continuity time space spatial dimension temporal dimension combined create spatiotemporal component spatiotemporal attention matrix derived spatiotemporal attention significance node updated merging spatiotemporal component input ultimately mlp\ able determine original dimension reduce loss information raw data use residual add raw data output shown red arrow fig second network module proposed gated dynamic graph convolution layer prominent module graph convolution layer fig input concatenation output sequence previous network original sequence embedded mlp\ spatiotemporal representation original data mapped mlp\ aggregate node information representation convolved two suggested adjacency matrix gated graph order update node information perform dynamic graph convolution operation output adaptive fusion dynamic adjacency matrix static adjacency matrix finally final reconstructed sequence output using mlp\ derive complemented data processing next sequence graph re-enter output data mlp\ embedding spatiotemporal representation point dynamic gated graph convolution layer data pre-processing concept begin description data processed definition concept given collection multivariate time series time step n-dimensional sensor consider sensor data node construct graph represents set sensor node graph node j=1 denotes relationship node node adjacent =1\ otherwise =0\ define raw data i-th sensor denotes data time interval i-th sensor indicates length data sensor represent missing variable introduce missing mask vector i=1 m\in t\times =\left\ array if\ is\ observed\\ if\ is\ missing\end array zero data missing one observed figure show construction graph training method filling data begin red fork incomplete data reveal real missing data whereas blue fork represent missing value generated random training paper construct graph sequence sensor node reconstruct data using proposed model define reconstruction error train val uniformly =\sum_ t=1 i=1 i=1 represents element-level error function using absolute squared error represents incomplete data node matrix reconstructed complete data matrix represents mask matrix formally objective multivariate time series filling find estimate minimizes reconstruction error training randomly simulate presence deficit order better train reconstruction task figure description training method reconstructing missing map sequence full size image unified spatiotemporal message passing layer dealing missing problem current advanced filling method use graph neural network filling traditional graph convolution message passing layer hand transfer node information space commonly modeling time space separately fusing information time space using technique like weighing situation hand bound result information loss irregular learning dynamic paper introduces new message passing layer spatiotemporal graph neural network order avoid fragmentation time–space continuum achieve direct transfer information time space modeling sensor moment node graph attention mechanism used calculate neighboring node enable message passing figure show example inter-neighbor messaging using moment one sensor long-term spatiotemporal dependency must considered effect different sensor different point time example moment sensor influenced moment sensor also moment example traffic jam one road may generate congestion another nearby road time later rainfall one area lead rainfall another area time later show treating spatial temporal correlation separately inappropriate figure messaging layer unified space–time full size image overcome problem paper proposes message-passing layer unify space–time enable node sense message neighbor time attention mechanism used assign corresponding weight neighboring node focus state similar neighboring node spatiotemporal graph reconstructed efficiently passing node neighborhood information establishing past-to-present connection neighbor paper attention mechanism aggregate set node information different moment sensor set node information neighbor learn reconstruct complete data representation figure illustrates learning process temporal data ith sensor time length set sensor form graph sequence missing graph reconstructed message passing layer spatiotemporal attention core initially encoding data high-dimensional data extracting significant spatiotemporal feature =mlp update node information time time =\sum_ j\in attention function =\frac exp i\in exp model parameter +mlp eventually use aggregation well residual block reconstruct incomplete data reconstructed graph sequence missing mask vector fill missing position data order obtain complete feature vector 1-m dynamic graph convolution filling method gating following message passing layer output utilized input next component learned graph convolution part use combination building dynamic adjacency matrix using distance static adjacency matrix shown fig input sequence mapped space–time representation n\times two adjacency matrix also defined one static adjacency matrix dist n\times using geographical distance sensor dynamic adjacency matrix learn n\times learned simultaneously connected sequence mask spatiotemporal representation fed graphical convolutional neural network modified gating function process sequence separately forward reverse direction one step time update reconstruct data adjacency matrix use forward backward transfer matrix adjacency matrix denoted =a/rowsum respectively figure dynamic graph convolution layer gating full size image fed gating graph convolutional neural network paper incorporates learning module time space replacing gru fully connected layer graph convolution layer selectively maintains information previous time step update current sequence =\sigma gcn\left dist learn t-1 =\sigma gcn\left dist learn t-1 =tanh\left gcn\left dist learn t-1 reset update gate respectively cell state information output previous time step symbol denote hadamard product concatenation operator respectively reset gate determines new input information combined previous information update gate used control extent state information previous moment brought current state computation forget dimensional information t-1 passed update adding dimensional information input current node gcn module context defined gcn =\sum_ k=0 represents set adjacency matrix dist learn represents input sequence model parameter number layer subsequently use adaptive fusion structure fuse static adjacency matrix dist dynamic adjacency matrix learn make adjustment dynamic adjacency matrix learn define dynamic adjacency matrix learn learn =softmax relu n\times c\times learnable parameter learn learn implicit relationship graph node enhance model ability capture spatial heterogeneity however limit much learn learn model trained learn fixed static adjacency matrix defined spatial distance contains geospatial information fuse adjacency matrix dist static spatial distance guide generation dynamic adjacency matrix capture deeper spatial feature subsequently fuse learn dist using adaptive fusion structure learn =\beta learn 1-\beta dist learn updated dynamic adjacency matrix learnable adaptive parameter factor fusion get adjacency matrix learn take hidden state output time step mlp\ one fill i.e. use mask guide missing position replace 1\right missing position data original data form filled data sequence continues learn fill function fill 1\right =mlp\left t-1 update hidden state updated sequence feature set adjacency matrix fed back gated graphical convolutional neural network feature mapped new spatiotemporal representation mlp\ continue processing input graph t+1 next time series method combine forward backward sequence produce final output whole data reconstruction experiment section evaluates four typical datasets often used field data imputation utilizing current state-of-the-art baseline well method provided paper final result show method proposed paper achieves advanced performance baseline datasets paper real datasets two domain air quality dataset transport domain dataset spatiotemporal characteristic datasets contain sensor timing data sensor geolocation data construct deficient better training experiment detail dataset shown table point missing block missing table detail relating datasets full size table air quality aqi dataset urban computing project zheng published several datasets including impact air quality human life particular air quality index aqi dataset contains hourly measurement six pollutant air quality monitoring station city china one-year period may april missing rate reached 25.67 conducted imputation experiment simplified version aqi dataset also taken account paper simplified version aqi-36 contains data air quality monitoring station 13.24 missing rate sake experiment comparability month march june september december dataset used test set paper grin setting time step chosen aqi aqi-36 time step chosen experiment geographical coordinate monitoring point dataset utilized generate static adjacency matrix article obtain adjacency matrix geographical distance node use threshold gaussian kernel shuman example weight edge i-th node j-th node certain threshold defined =\mathrm exp -\frac dist\left j\right dist\left j\right dist\left calculated geolocation distance function width gaussian kernel threshold value maintain experimental consistency set standard deviation geographical distance provided dataset distance traffic flow datasets field data imputation traffic flow data also commonly used dataset verify effectiveness imputation paper therefore pems-bay metr-la datasets metr-la contains month sensor reading sensor los angeles county motorway jagadish sampling rate min pems-ba contains month data traffic sensor san francisco bay area sampling rate min datasets time step i.e data similarly leigh dataset provided sensor geolocation data construct static adjacency matrix using threshold gaussian kernel paper consistent experimental setup grin using data training validation set test set simulate presence missing data referring setting grin block loss i.e. step sensor discard available data random point loss simply mask available data random baseline approach filling method proposed paper complementary spatiotemporal dimension mainly considers advanced filling method comparison var vector autoregressive one-step ahead predictor set batch size learning rate 0.0005 using sgd train model predict next value using last five historical observation saits self-attention fill missing data time series setting hyperparameters use hyperparameter range original paper brit model data bidirectional recursive approach network hyperparameters adopted aqi-36 dataset hidden state size set aqi metr-la datasets compared pems-ba dataset e2gan end-to-end generative model estimate missing value multivariate time series parameter setting consistent brit rgain gain bidirectional recursive encoder decoder parameter setting consistent found brit csdi new time series imputation method fraction-based diffusion model fraction-based diffusion model based observed data fill missing value grin reconstructs missing data different channel multivariate time series learning spatiotemporal representation message passing parameter setting original paper well simple statistical filler method mean mean fill mouse algorithm multiple interpolation chain equation knn k-nearest neighbor algorithm matrix decomposition algorithm experimental setup experiment paper implemented using pytorch trained experimentally validated nvidia teslav100 gpu adgcn algorithm paper adam optimizer used trained using cosine learning rate scheduler initial value learning rate 0.001 round used training randomly sampled batch element per round set line grin evaluation method three metric mae mean absolute error mse mean square error mape mean absolute percentage error evaluate performance model mae\left imputation target mask imputation_ target_ mask_ mse\left imputation target mask imputation_ target_ mask_ mape\left imputation target mask imputation_ target_ mask_ mask_ hyperparameter experiment section design hyperparameter experiment find efficient hyperparameters experiment keep batch size setting baseline change size hidden layer model number layer graph convolution number graph convolution layer set hidden layer size set figure show result hyperparametric test aqi dataset air quality figure hyperparameter experimental result full size image figure show result hyperparametric test aqi dataset air quality model achieves optimal performance batch size hidden layer size number graph convolution layer result hyperparameter setting used upcoming experiment experimental result section performance baseline compared model proposed paper four real data set two classical domain table show experimental result model baseline air quality dataset table show result complementary performance traffic flow dataset result show adgcn outperformed baseline case table comparison model performance average experiment filled air quality domain dataset full size table table comparison model performance average experimental fill traffic flow domain dataset full size table experimental result show adgcn achieves best performance complementing spatiotemporal data different scenario statistical approach often utilized efficiently fill data deep learning method deep learning method seek correlation data well extract temporal spatial aspect data rgain learns distribution real data using generative adversarial network temporal reminder matrix classifier estimate missing value converge true data distribution filling brit based recurrent neural network directly learn missing value bidirectional recursive dynamical system saits self-attentive mechanism capture temporal dependency feature correlation impute data csdi hand used diffusion model fill data csdi produce better result aqi-36 dataset node model yield better performance switch larger aqi dataset node also large traffic datasets model produce better result comparison spatially distinctive nature dataset paper csdi may achieve optimal result however e2gan rgain brit csdi saits ignore spatiotemporal property data use spatial property fill considering temporal nature data furthermore mpgru gnn-based one-step prediction similar dcrnn grin enhancement intending rebuild missing data distinct channel multivariate time series learning spatiotemporal representation message passing paper proposes adgcn address fact time-dependent cycle neighbor message-passing node grin may delayed dynamic severing continuity time space unify temporal spatial messaging layer messaging dynamically adapt adjacency matrix spatial node neighborhood relationship conclusion experimental result show adgcn capture temporal spatial information achieving best filling performance spatiotemporal data imputation test robustness experiment table show well model fill missing data however section raise rate missing data experimental validation order confirm model robustness two large traffic speed datasets described used example experiment example visualize missing data rate scenario constructed every min data san francisco bay area pems-bay traffic dataset entire day may figure show distribution data different deletion rate heat map vertical coordinate denotes various detector horizontal coordinate denotes time day data taken degree color denotes various speed rate missingness rise observed dataset contains increasing number zero item represented increasing number black dot heat map confirm stability robustness model comparison experiment baseline run various deletion rate table show result robustness experiment figure heat map pems-bay dataset different deletion rate full size image table comparison model mae result data absence rate increase full size table shown table proposed adgcn model show excellent performance case complementary error state-of-the-art model therefore model proposed paper good robustness increase missing rate model still show excellent filling performance ablation experiment section paper ablation experiment verify effectiveness two-part module adgcn adgcn separated three component message-passing layer without attention mechanism dgcn model removing dynamic graph adjacency matrix agcn well full adgcn model addition replace fully connected layer gru graph convolution gated graph dynamic graph convolution module therefore order verify validity transformation switch back fully connected structure gru experiment compare model performance four model compared table table ablation experiment mae value average time indicate missing point block missing setting respectively full size table since study ignore continuity time space model design process established sensor moment node graph used attention mechanism give node neighbor corresponding weight update graph graph constructed dynamic graph convolution module gating created recreate missing graph sequence via graph convolution adjacency matrix merging static distance dynamically adaptive adjacency matrix based spatiotemporal data result table clear adgcn obtain best complementary effect matter part missing also replace fully connected layer gru graph convolution operation better integrate temporal spatial information experiment show use graph convolution work better conclusion paper proposes dynamic graph neural network reconstruction model adgcn capable unifying time space method treat sensor state moment node graph update graph giving weight attention mechanism complete construction unified temporal spatial messaging layer dynamic spatial correlation represented dynamic adaptive module input spatiotemporal information used construct graph adjacency matrix structure fused defined static distance adjacency matrix adgcn model explores connection node network point time order capture hidden temporal spatial correlation simulate spatial dynamic node correlation experiment four real-world datasets show combining temporal spatial continuum dynamically constructing spatial node interaction improves data imputation additionally test various set parameter value experiment model training phase choosing best one demonstrating model adgcn proposed paper outperforms state-of-the-art baseline verify robustness adgcn paper increase missing rate two major traffic datasets verify stability model experimental result show imputation performance model decrease missing rate increase still yield best performance compared state-of-the-art imputation method therefore model good robustness addition paper ablation experiment verify validity module design adgcn model model adgcn proposed paper outperforms state-of-the-art baseline