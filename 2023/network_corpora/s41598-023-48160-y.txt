introduction keratoconus kcn non-inflammatory disease characterized bilateral progressive corneal thinning result abnormally steep cornea decreased vision potentially leading vision loss detected treated early stage although underlying cause kcn unknown ophthalmologist link chronic disease eye rubbing genetic inheritance kcn progression may proceed quickly slowly may come end point keratoconus affect people general population prevalence condition adult child considerably increased recent year asian population approximately four time higher prevalence kcn compared ethnic group highest prevalence observed mediterranean region middle east iran according epidemiological study released recent year 0.3 case per 100,000 person 0.0003 reported russia 2.3 india 2.5 iran field machine learning researcher face significant challenge obtaining sufficient medical image datasets due difficulty capturing data well time-consuming process acquiring labeling requires considerable effort researcher specialist address issue limited datasets various study explored use data augmentation popular technique computer vision advantage human evaluation term data processing information integration diagnostic speed date many method implementing machine learning support vector machine decision tree neural network recommended many scientific field multilayered neural network specifically convolutional neural network cnns recently accomplished outstanding effect variety image classification several study employed machine learning identify keratoconus however majority either used topographic numeric index obtained placido disc-based corneal topographer tomographic numeric index acquired using scanning slit tomographer rotating scheimpflug camera impressive capability convolutional neural network cnns pattern recognition image classification task make highly suitable option automating analysis color-coded image deep learning method particular deep convolutional neural network cnns used identify kcn using color-coded corneal map elevation curvature thickness despite fact model generally need larger number sample research typically used limited subset image fewer image zeboulon detected kcn history refractive surgery using sizable dataset corneal image distinguished kcn normal high degree accuracy additionally since developing refining deep cnn model often computationally expensive model execute quickly like current model better chance incorporated clinical setting study innovative approach involving variational auto encoders vae employed generate augment image employed substantial dataset comprising corneal image train ass four deep convolutional neural network cnn model purpose diagnosing keratoconus three method utilized transfer learning fine-tuning pretrained model customized dataset fourth method employed customized cnn proposed model developed scratch model became expert identifying kcn feature specific corneal map variety topographic pattern instead complex topographic index result keratoconus group consisted patient men woman mean age 33.27 8.09 year normal group consisted subject refractive surgery candidate men woman mean age 34.56 8.76 year keratoconus group younger normal group substantially different noted concerning sex distribution table table characteristic population full size table table present descriptive statistic topographical parameter group indicating significant difference index keratoconus normal group table topographic parameter keratoconus normal full size table order address challenge limited data deep learning training expand dataset conducted training using vae generative model training encompassed entire dataset comprised total image dataset divided two category image categorized normal image categorized keratoconus training process resulted cumulative loss approximately 6.667 loss included reconstruction loss 5.533 kullback–leibler loss approximately 1.133 latest iteration model fig figure vae model training loss metric full size image opted train generative model entire dataset encompassing image class decision based efficiency demonstrated vae network clustering discerning feature distinction class efficiency particularly evident vae function unsupervised model solely aimed uncovering data pattern notably experimentation confirmed training generative model like vae normal keratoconus class separately yield discernible advantage training image type simultaneously clearly depicted fig underscore significant pattern recognition capability model figure visualization clustering vae full size image improved visualization network outcome adopted method wherein designated specific range mean standard deviation parameter within latent space parameter meticulously selected generate diverse set latent variable employed input pre-trained decoder model study decoder model weight undergone careful training dataset loaded initialized varied latent variable input approach allowed generate series image across specified parameter range specifically employed different value mean standard deviation parameter maintaining consistent step separation value result created total novel image sample encompassing various type pattern depicted fig figure output reconstruction process varying among discriminative cone type full size image demonstrated fig illustrates original image utilized part test dataset demonstrates initial version output training vae model using data one clinic subsequently increase number image multiple clinic optimizing vae model final version output achieved satisfactory level quality confidence learning significant discriminative cone type pattern according fig model ability produce synthetic image closely resemble original image figure overview progression vae output developing various version original image initial model output final generated image full size image developed cnn model classifying corneal type case keratoconus normal generative image vae model table demonstrated utilization synthesized image training process increased classification performance training cnn model showed reasonable accuracy evidence overfitting noted test dataset applied fig accuracy sensitivity specificity ppv npv auc shown table highest accuracy level 0.993 obtained employing vgg16 model sensitivity 0.994 specificity 0.987 followed resnet152-v2 0.959 sensitivity 0.959 specificity 0.953 efficientnet-b0 0.952 sensitivity 0.944 specificity 0.983 customized cnn 0.974 sensitivity 0.980 specificity 0.966 area receiver operator characteristic curve 0.988 vgg 0.964 resnet152-v2 0.963 efficientnet-b0 0.973 customized cnn illustrated fig bottom performance model deemed acceptable vgg16 exhibiting best performance table result cnn model generating image vae model full size table figure training result auc cnn model auc 0.99 vgg16 top left 0.96 resnet152 top middle 0.96 efficientnet-b0 top right 0.97 customized cnn bottom full size image outcome classification shown fig using vgg16 model example normal group consists flat topographic feature regular astigmatism keratoconus group consists steep topographic feature according algorithm normal predicted top bottom case respectively keratoconus feature predicted top bottom case respectively result present algorithm effectively correctly distinguished keratoconus normal figure example trained vgg16 model full size image additionally calculated confusion matrix ass performance quality learning process confusion matrix vgg16 presented fig image thirteen misclassifications including five case kcn eye incorrectly classified normal figure illustrates example eye misclassified model vgg16 figure confusion matrix vgg model kcn diagnosis obtained evaluation step test dataset full size image figure four sample image misclassified model vgg16 two normal eye misclassified kcn two kcn eye misclassified normal full size image also included grad-cam output widely accepted approach visualizing feature map pinpointing salient region interest within final layer deep cnn model quality visualization enhanced application heat map mixture technique refinement contributes production higher-quality figure turn serf robust mean validating model associated trained parameter fig figure visualization trained cnn model left column show original topographic image right column heat map visualization result grad-cam method demonstrates significant area topographic image full size image discussion developed multiple model classify keratoconus non-invasive corneal topography image order solve problem limitation previous model employed novel design approach large representative datasets often necessary model effectively learn various feature associated underlying condition study utilized relatively large dataset consisting corneal image employed vae model generate augment image vaes great feature extraction utilization vae assist network acquiring ability generate output continuous distribution enabling process diverse input produce desired outcome worth mentioning one capability auto-encoders unsupervised learning model cluster data assign relevant class label study despite predetermined label reconstructed data aspect applied effective representation customized vae vae model used synthesize image original image resulting image displayed fig high quality image evident also apparent structure morphology image stable study found diagnostic accuracy vgg16 resnet152-v2 efficientnet-b0 customized cnn classifier improved significantly using synthetic data sample specifically diagnostic outcome classifier increased 0.962 0.993 0.939 0.959 0.943 0.952 0.950 0.974 respectively result table indicate use synthetic data sample enhance variability input dataset leading precise clinical decision researcher also utilized approach data augmentation enhance training process method involve generating high-quality sample image use generative model called generative adversarial network gans corneal disease diagnosis task hwang demonstrated synthetic data augmentation using cgans improves accuracy approximately compared traditional data augmentation method xception classifier achieved highest level performance 90.5 using synthesized data utilization conditional gan data augmentation found enhance segmentation accuracy retinal oct image reported previous study several study gan utilized increase amount data available analysis various eye condition instance used augment anterior oct image angle-closure glaucoma ocular surface image conjunctival disease corneal topography image keratoconus detection evaluated performance vgg-16 dcnns classify test set using six distinct combination original synthesized image training process similar study vgg16 model obtained highest accuracy 99.78 finding suggest incorporating synthetic data sample training process medical image classifier improve diagnostic accuracy ultimately benefit patient several study exclusively employed corneal topography parameter kmax i-s kisa utilized parameter however still challenge utilization including high false-positive rate complexity overlap parameter normal kcn eye number accessible parameter make interpretation complicated study highly depend manually created feature machine-extracted index svm logistic regression random forest decision tree neural network model offer complete solution learns extract feature without supervision without need manually created feature produced parameter .since color-coded map provide visual information topographic tomographic numeric index learning employed entire image color-coded map deep learning study developed multiple model trained extract pertinent deep feature corneal topographic map detect kcn result demonstrated utilization deep learning offered highest accuracy 0.99 auc 0.99 using vgg16 model distinguishing kcn normal group table finding suggest deep learning potentially improve diagnostic precision keratoconus model exhibited sensitivity specificity exceeding 0.94 vgg16 model achieved highest sensitivity 0.99 closely followed customized cnn sensitivity 0.98 vgg16 efficientnet-b0 model demonstrated highest specificity 0.98 high sensitivity indicates low rate false-negative prediction implied trained cnn model appropriate keratoconus screening furthermore model exhibit high specificity indicating strong predictive capability normal group central cone asymmetric bowtie skewed radial axis ab/srax fig bottom two typical topographic pattern keratoconus algorithm able recognize addition inferior steep pattern figure present sample image eye misclassified vgg16 model sample thirteen misclassifications including five kcn-positive eye incorrectly labeled normal reason issue due similarity regular astigmatism pattern normal cornea bowtie keratoconus study demonstrated customized cnn model promising approach achieving accurate prediction minimizing network complexity although vgg16 model outperformed model study customized cnn model achieved satisfactory result accuracy auc 0.97 much faster processing speed compared model strength study may due ease training network extract suitable feature data fewer convolutional layer relevant filter therefore deep cnns strong feature learning obtaining suitable weight possible achieve similar prediction quality customized cnn model much network complexity optimal time furthermore gradcam result depicted fig demonstrate model concentrate attention central area considered region clinical significance study abdülhüssein vgg-16 pre-trained cnn model employed identify distinct topographic map classification accuracy achieved sag map 88.8 98.9 94.8 94.5 respectively important mention evaluation conducted separate training testing set without validation set comparison previous research kcn detection provided table also contains information device used number eye model used evaluation method table detection kcn corneal topographic image previous literature full size table although utilized substantial dataset reliable platform study potential limitation first since data gathered two different clinical setting mashhad essential collect data population race order independently evaluate model assure generalizability second study used front topographic corneal map may produce comparable result topographic map different platform however future research investigate impact fusing different corneal map combination accuracy generalizability result third corneal disorder subclinical keratoconus included study due insufficient availability relevant image research recommended explore potential using gan model corneal image synthesis order achieve better result evaluate difference corneal map normal eye eye suspected kcn method study population retrospective study received approval two crowded tertiary eye clinic namely noorafarin didar mashhad conducted accordance principle outlined declaration helsinki informed consent provided patient initially collected corneal image overall subject included september june patient candidate refractive surgery subject previous ocular surgery trauma corneal degeneration contact lens discontinuation three week excluded ultimately total subject image included study sample size follows image normal cornea subject image kcn patient medical record patient reviewed retrieved confirm diagnosis kcn patient record consisted result optometry ophthalmology examination including slit lamp biomicroscopy dry cycloplegic refraction uncorrected best-corrected visual acuity diagnose at-risk cornea corneal topography tomography biomechanical corneal characteristic evaluated using tomey tms-4n tomey corp. pentacam oculus wetzlar germany corvis oculus wetzlar germany device respectively three corneal specialist involved assessment diagnosis labeling keratoconus initial corneal topographic map collected use tms-4n tomey corporation nagoya japan data preprocessing algorithm first data preprocessing applied eliminate irrelevant element image word number achieve utilized computer vision algorithm crop extract cornea pattern image hsv mask applied filter segment cornea extra margin removed cornea obtained next step preprocessing observed significant number image acquired high-resolution medical imaging device tms-4 contaminated regular noise solution noise removal function designed denoise image process applied individually image eventually collection high-quality image normalized size obtained training deep learning model figure show raw sample data regular noise result preprocessing figure raw sample data regular noise full size image variational autoencoder vae augment image one major challenge faced medical field scarcity large-scale datasets study proposed innovative approach address issue utilizing variational auto-encoders vaes generate augment image auto encoders combination statistic information theory combined power deep neural network efficient solving generative problem high dimensional data variational auto encoders particular focus understanding latent representation data provide way generate new sample using probabilistic approach vaes deep neural network utilizes unsupervised learning composed two main component encoder decoder network separated layer known latent variable layer latent space vaes often employed generative model able extract useful feature learn suitable representation data encoder generate output format original data using decoder take latent representation input encoder component vae presented image input produce two-parameter latent vector representation sequence down-sampling operation convolution similarly decoder component given one-parameter latent vector representation reconstructs original input data via series up-sampling operation transposed convolution research employed vae model comprises encoder decoder network deep convolutional neural network convolutional layer fully connected layer addition input layer shape dimension respectively architecture encoder network 64-32-16-128 represents number filter convolutional layer number hidden neuron fully connected dense layer architecture decoder network 2704-16-32-64 number hidden neuron deep net applying convolutional layer performing down-sampling encoding process feature vector size obtained flatten layer passed dense layer input neuron output parameter mean standard deviation data distribution two parameter delivered latent space single sampling variable provided latent layer passed decoder model input sample order mentioned encoding procedure reversed decoder model take single sampling variable vector input passed dense layer number neuron equal number extracted feature encoder followed reshape layer resulting feature vector subjected series up-sampling step using three consecutive transposed convolutional layer resulting final output vector original size input sample figure show vae architecture developed generate image corneal topographics figure architecture vae case study shown figure preprocessed sample first converted grayscale fed network final result decoded back original shape color space full size image loss function vae model like variational auto-encoders based loss function namely reconstruction loss kullback–leibler divergence reconstruction error indication quality generated sample lower error optimized generative performance loss however aim measure divergence distance dissimilarity two distribution based information theory used regularization technique latent space vaes interpreted bayesian inference model prior distribution latent variable represented generative model observation defined z|x inference model latent representation data defined z|x objective vae loss function minimize divergence distance prior distribution z|x inferred distribution z|x loss min q\left z|x\right p\left z|x\right instead trying minimize divergence term simplify loss function re-arranging maximization objective using decoder output input data follow loss= q\left z|y\right log p\left y|z\right kl\left q\left z|x\right first term equation describes log-likelihood reconstruction second term represents attempt make learned distribution true prior distribution similar possible minimizing distance hence total loss function vae model input data encoder i=1 output sample decoder i=1 latent variable shown loss=\sum_ i=1 q\left log p\left q\left p\left z\right training vae model necessary prepare raw dataset converting image grayscale adjusting resolution unsupervised generative model tend perform better working single channel image preprocessed way custom preprocessing method designed convert image grayscale preserving significance color spectrum border feature image later classification task one key feature distinguishes keratoconus patient normal one organization cornea color clinical image therefore standard predefined method opencv grayscale conversion method could used would maintain important feature image figure illustrates difference conversion figure comparison grayscale conversion result opencv manually implemented method full size image purpose training used random horizontal flip rotation augment training dataset learning rate 0.0001 rmsprop optimizer training task performed epoch across distinct version vae model beginning initial model characterized relatively lower implementation complexity extending latest version distinguished enhanced code efficiency optimized model parameter trained accurate vae model raw dataset constructed new appropriate image topographic picture divided subsequent two datasets training test datasets used image keratoconus normal training dataset image keratoconus normal test dataset allocated training dataset validation dataset unlike training dataset comprised combination generated original image test dataset exclusively consisted original image approach adopted ensure accuracy reliability model metric measurement test dataset involve training process deep learning architecture visualization study presented four method classifying patient keratoconus normal sample using convolutional neural network cnn architecture three method based transfer learning fine-tuning pretrained model including vgg16 efficientnet-b0 resnet152 model custom dataset fourth method bespoke cnn model implemented scratch vgg16 model 13-layer convolutional neural network cnn composed max-pooling layer fully connected layer characterized use max-pooling layer every convolution increase number filter first convolutional layer last final prediction model made softmax classifying layer stacked top flattened fully connected dense layer efficientnet-b0 model foundation efficientnet family utilizes cnn architecture aim uniformly scaling dimension depth width resolution compound scaling method balance need additional layer increase receptive field channel capture detailed pattern larger image base model constructed mobile inverted bottleneck conv mbconv block mobilenetv2 along squeeze-and-excitation block deep residual network similarly utilizes combination convolutional pooling activation fully-connected layer differs network due identity connection residual block help prevent vanishing gradient problem backpropagation process model comprises bottleneck design block consisting convolutional layer network concludes average pooling layer fully-connected layer single neuron producing binary classification output three cnns implemented pre-trained weight imagenet dataset shape input layer order augment performance network data augmentation layer added consisting random horizontal flip random rotation followed preprocessing layer rescaled pixel range cnns linked previous layer classification head added top including global average pooling layer followed dense layer neuron dropout rate 0.2 finally single neuron prediction layer added make final prediction figure demonstrates mentioned structure figure architecture present cnns keratoconus full size image study also utilized customized cnn architecture designed process 3-channeled image size network comprised three convolutional layer filter respectively stride convolutional layer connected two fully connected layer dropout layer 0.25 rate placed final prediction made single neuron layer sigmoid activation function training pretrained network common approach utilize feature learned model trained larger dataset domain dealing small dataset achieved instantiating pre-trained model appending fully-connected classifier pre-trained model fixed weight classifier updated training scenario convolutional base extracted feature related image classifier trained determine image class based extracted feature consequently model trained validated epoch using learning rate 0.0001 adam optimizer binary cross-entropy loss function layer base cnn model kept frozen state feature extraction experiment top layer pre-trained network trained keeping base model weight unchanged improve performance top layer pre-trained model fine-tuned making number convolutional layer trainable cnn model fine-tuning process carried retraining whole network additional epoch forcing weight tuned generic feature map feature associated specifically dataset customized cnn model trained using fivefold cross-validation approach random shuffling dataset fold trained epoch learning rate loss function consistent used pre-trained cnn model rmsprop optimization algorithm utilized place adam optimizer computer hardware software deep learning computation described study executed personal computer equipped amd ryzen core processor 3.59 ghz nvidia geforce gtx gpu deep neural network developed using python programming language utilizing tensorflow 2.3.0 kera 2.4.3 library statistical analysis demographic data chi-square test employed compare gender distribution keratoconus normal group t-test used ass difference age performance algorithm evaluated based measure area receiver operating characteristic curve auc confusion matrix accuracy sensitivity specificity positive predictive value ppv negative predictive value npv roc curve utilized specify overall predictive accuracy examined parameter indicated auc calculate specificity sensitivity distinguishing kcn normal eye optimal cutoff point index received roc curve selecting point closest maximum value sensitivity equal specificity statistical analysis achieved using spss software spss 24.0 spss inc. chicago usa p-value 0.05 considered statistically significant additional metric obtained using scikit-learn tensorflow platform conclusion study utilized relatively large dataset consisting image vae approach construct various cnn model extracting deep feature corneal topographic map result demonstrate effectiveness transfer learning generating efficient deep classifier leading highly accurate model distinguishing kcn normal eye demonstrated utilization synthesized image training process increased classification performance implementation automated keratoconus model show great potential enhancing clinical practice aiding corneal specialist identification management kcn patient contributing reduction number corneal transplant case