introduction medical datasets often contain inherent error due uncertain diagnosis potential subjectivity medical practitioner interpretation test result confounding variable stemming underlying biological complexity patient result medical test therefore represent measurement always perfectly match ground truth diagnosis condition patient error ground truth outcome represent significant challenge development artificial intelligence healthcare application presence error medical datasets severely hamper reliability performance algorithm potentially placing patient risk good quality error-free data also critical emerging application precision medicine well clinical trial data used support approval new patient treatment identifying error datasets straightforward first manual identification error haphazard lack scalability secondly datasets needed train model many industry already size manual data verification feasible industry healthcare privacy policy law may prevent third party conducting manual verification data source mislabeling rely judgment medical professional contain certain element subjectivity interpretation medical test outcome diagnosis always manually identified one key insight drawn application deep learning identifying poor quality data issue quality fall different category mislabeled data feature data clearly identifiable simply incorrectly labeled i.e data error noisy data data unclear ambiguous lacking feature make definitive conclusion regarding ground truth outcome often called feature noise two type factor present dataset negatively impact performance reliability able identify given datapoint dataset lie spectrum label-noise therefore paramount utility creating reliable work novel deep learning method automatic priori identification data error presented intended integrated training process model extends untrainable data cleansing udc technique label-clustering algorithm novel algorithm denote ldc generates continuous label-noise confidence score given dataset used identify likelihood datapoint either correct erroneous mislabeled noisy unclear high score datapoint indicates high degree confidence datapoint mislabeled low score indicates datapoint likely correctly labeled medium score indicates high confidence label either way datapoint noisy ground truth label known performance ldc algorithm identifying error data measured using intersection union iou score error identification accuracy defined experiment design section iou score measure well two subset data overlap error data correctly identified data identified error actually error iou take value 1.0 error undetected iou value drop similarly data wrongly identified error iou value also drop minimum value 0.0 thus iou score penalizes failure identify error also wrongly identifying error correct data ground truth label known uncertain performance ldc algorithm assessed using model performance improvement ldc cleansing training data ldc tested range diverse datasets different field physiology including human activity recognition har time-series data patient treatment record human oocyte image measurement performance ldc achieved training model original poor quality training set training ldc cleansed training set comparing two cleansed validation set firstly training cleansed dataset would typically stable reduced oscillating loss function epoch epoch due mislabeled data secondly testing model cleansed validation set show cleansing allowed consistent reliable model trained absence mislabeled confusing data result showed high level accuracy detecting poor quality data dramatic improvement model performance trained ldc cleansed datasets result indicated deep learning label-clustering approach efficient method automating data cleansing record image data allowing subsequent creation increasingly reliable scalable novel contribution work summarized introduction efficient robust data cleansing method ldc identifying error datasets especially situation manual method impractical impossible introduced novel metric-based method effectively measuring ability ldc identify error noisy label demonstration ldc across multiple type data—time-series record-based image-based medical datasets experimental result showed uplift performance due application ldc introduced histogram-based heuristic method visualization identifying subsection dataset may mislabeled simply noisy data hard case article organized follows related work summarized related work section method described method section including experimental design experiment design section label-noise confidence algorithm label-noise confidence algorithm section composition non-medical medical datasets section dataset composition setting section result presented result section divided section topic model consensus approach compared new label-clustering method har test case comparing label-clustering different approach human activity recognition section including comparison existing loss function robust label noise ldc method applied har medical record patient care application ldc har patient care section medical image denuded human oocyte examined application ldc labeled oocyte image section discussion presented discussion section related work recent development field machine learning cleansing poor quality datasets fall several category use updated model architecture robust source feature noise simultaneously overfitting training dataset sophisticated regularization technique dropout batch-norm augmentation weight decay partially improve model robustness label noise robust loss function used training selecting subset data contains cleaner label typically involves kind hybrid learning multi-network multi-round learning together loss reweighting improvement neural network architecture maintain robustness label noise training typically involve introduction new layer specific functionality either attempt estimate true label training nlnn label-flip modeling otherwise reduce effect label noise training dropout regularization one method reducing effect label noise mixup synthesizes new training data combining pair datapoints label particular distribution purported advantageous due increased difficulty overtraining interpolation incorrect label compared correct label work dropout batch-norm augmentation weight decay approach used experiment maintain model robustness focusing data cleansing predominantly improving loss function unbiased estimator introduced training process modify loss function robust purportedly help minimize risk random classification noise dataset doe directly address deleterious effect caused mislabeling working well simple case limited number class classification problem different approach involves adding label noise model deep learning framework output log-likelihood value method presupposes portion dataset reliably identified noise requiring prior annotation thus limiting applicability outside original domain recent method adopted bayesian framework gaussian-shaped prior weight added minimizing new loss function capture new noise parameter output model rather data inferred noise associated inherent randomness data excludes effect systematic mislabeling stemming confounding factor robust loss function explored comparing robust loss function approach binary multi-class classification section comparator data cleansing exhibiting limited benefit especially case binary classification data cleansing many traditional method used identify remove reclassify data suspected mislabeling bagging boosting -nearest neighbor form outlier detection sophisticated hybrid method proposed iterative form self-learning multi-round learning collaborative co-training selection representative data epoch performing label correction step prior starting next epoch method allow real-time detection noise necessarily provide transparency data noisy mislabeled degree confidence classification therefore useful medical application consideration paramount focus present work data cleansing diverse array method described used complement advantage data cleansing assist explainability triaging flagged data analysis identification possible source mislabeling confounding factor leading new insight dataset composition also assist identifying subset data model might expected work best especially important medical datasets mislabeling occur due unclear diagnosis subjectivity medical test result patient medical indication may explicitly apparent dataset work build previously developed process -fold cross validation obtain aggregate model prediction method novel robustly detect noise using multiple contrasting neural network different initial condition architecture carry consensus approach datapoint rather constrained rely inference prediction single model ameliorates one main weakness data cleansing over-cleansing removal many correctly-labeled datapoints reduced measured iou score additionally computational inefficiency drastically reduced entering score obtained one model label-clustering algorithm obtain new label-noise confidence score determined without knowledge quality datapoint advance method experiment design two type problem time-series and/or record-based datasets image-based datasets require different model architecture experiment two datasets defined training/validation set treated together using fold cross validation method holdback set additionally experiment model hyperparameters tuned selected running multiple model training round different set hyperparameters using training set assessing model performance validation set ratio training validation set size 80:20 using fold cross validation result reported final holdback set distinguish cleansed uncleansed reporting set holdback set blind set ldc applied called test set otherwise called validation set problem type log-loss utilized ass best model performance model reported using total accuracy total number correctly predicted datapoints across class specificity sensitivity metric unless otherwise stated intersection union score intersection union iou score represents one option assessment performance error identification using udc ldc method iou score defined term total number datapoints correctly identified error correct known intersection prediction ground truth total number datapoints either actual error predicted error actual predicted known union iou correct actual\ predicted error identification method identifies actual error within data simultaneously doe identify correct data error intersection correct exactly equal union actual predicted algorithm made prediction equal number total actual error data iou score equal error identification accuracy error identification accuracy eia also used assessment error identification performance lead cleaner definition cleansing performance training removal superfluous clean data problematic eia value doe penalize removal correct data unlike iou useful accuracy measure method applied big data removal clean datapoints typically deteriorates model training dataset size near minimum threshold size eia defined follows eia correct predicted predicted number prediction made error identification method deep learning architecture record-based experiment model defined several 1d-cnn layer followed dropout layer regularization output feature flattened one-dimensional vector passed fully connected layer reaching output layer used prediction number 1d-cnn fully connected layer along feature map kernel size made configurable fine-tuned along model architecture conventional hyperparameters multi-layer perceptron mlp model also used compared performance 1d-cnn model consistently showed inferior result 1d-cnn model sufficient representing clean har dataset without overfitting prior testing effectiveness data cleansing method 1d-cnn model rectified adam radam version stochastic gradient descent used network optimization image-based experiment detector segmentation model used image pre-processing architecture parameter defined binary classification model used based pre-processed image input architecture parameter also defined deep learning run work make use data normalization pre-processing step dropout layer improve robustness label noise regularization step image processing described detector model faster r-cnn model used included resnet50 feature pyramid network backbone expects input image scaled height width pixel keep resolution consistent object detection output model bounding box corresponding detected object non-maximum suppression algorithm also used threshold value set 0.25 score threshold set 0.4 minimum box heigh width admitted pixel small detected box least one box edge smaller pixel lie completely within another box removed prevent model under-fitting boundary case two over-lapping box output larger box encompassing two box selected segmentation model u-net architecture resnet-50 encoder trained detect zona pellucida region pre-annotated oocyte image california fertility partner segmentation threshold 0.7 segmentation width height pixel uncleansed validation set comprised image performance final model evaluated using image iou score classification model deep learning architecture utilized image classification included resnet-34 resnet-50 wide_resnet-50_2 densenet-121 densenet-161 pre-trained using imagenet run epoch learning rate ranged 1.0e-4 3.0e-4 using cosine annealing scheduling technique momentum value 0.9 0.95 dropout rate 0.10 0.15 batch size uniform rgb normalization stochastic gradient descent sgd used network optimization categorical cross entropy loss function throughout fold cross validation used identifying model consensus udc used promote training data randomization varying evaluation condition ldc image classification training run make use batch-norm weight decay heavy augmentation cropping scaling rotation color rotation blurring coarse-dropout regularization technique parameter used three type image segmentation defined application ldc labeled oocyte image section label-noise confidence algorithm figure show visual representation step ldc identifying error contrasting model configuration trained given dataset achieved changing architecture hyperparameters performing -fold cross validation pictured model inference datapoint label-clustering algorithm applied described distance center gravity normalized datapoint corresponding label-noise confidence score score may binned histogram show distribution noise mislabeling dataset threshold may set removal error prior training final model figure workflow ldc method illustrated binary multi-class classification problem process model single architecture hyperparameter set shown process involving fold cross validation may repeated multiple time different model setting model may contribute evenly generated histogram shown full size image reasoning behind choice constituent model ldc method typically one model trained dataset contain inherent bias exhibited preference classifying one subset data case one whole class better another due small difference clarity feature learned dataset order mitigate inherent bias one particular model different fold data used validation set different hyperparameters selected consensus multiple contrasting model used drive error identification central point model must trained different subsection i.e cross-validation phase training set using rest validation set model may different architecture hyperparameters inherent bias thus making consensus among model predicted label datapoint meaningful model trained cross-validation phase setting concordance would likely high datapoints would add new information training large number neural network time-consuming expensive ldc customized high-performing model configuration needed generate continuous label-noise confidence score label-noise confidence score defined likelihood input sample incorrectly labeled identified uninformative labeled particular class score used identify poor quality data part algorithm note use various model architecture -fold cross validation ldc algorithm algorithm helped introduce variation respect network structure training data randomization respectively rotation validation set fold increased diversity initial condition model considered histogram value increasing x-axis show data sample distribution different label-noise confidence score algorithm interpreted follows model architecture associated hyperparameter set -fold cross validation deployed line thus model architecture utilized repetitively -phase time phase model trained different training dataset i\right calibrated validation set i\right training best model i\right associated cross-validation phase model architecture obtained line best epoch selection procedure involves finding best value given evaluation metric validation set unless otherwise mentioned log loss selected key evaluation metric important validation dataset included cleansing process needed effectively select good candidate model prior reporting holdback test set prediction confidence score i\right input sample calculated line running i\right evaluation mode model inference made entire dataset i\right would represent likely belonged class class e.g case binary classification problem label-noise confidence score i\right computed via function line described follows mean clustering model deployed fitted passing i\right whole dataset input center gravity returned one centroid per class dataset mandated word class label associated single cluster represented -means resulting activation map inter-cluster euclidean distance gravitational center intra-cluster distance class center calculated relative noise confident score i\right =a-b\ calculated larger score likely considered noise/mislabeled i.e. located relatively close center class procedure repeated sample dataset final label-noise confidence score calculated averaging result obtained model cross-validation phase line normalized range represent label-noise confidence score method inspired silhouette coefficient method given relative euclidean distance input sample different cluster center rest algorithm straightforward pre-defined filtering threshold utilized rule highly suspected noisy sample dataset threshold corresponding number noisy sample practically estimated based calculation number sample misclassified relatively high predicted confidence score note holdout test set never involved cleansing process withdrawn prior definition application ldc ldc completed low-quality data excluded obtain cleansed dataset holdout validation set also withdrawn measure extent cleansing successful final model trained newly cleansed training set reporting cleansed validation set reliable measurement performance may reported holdout test set dataset composition setting time-series dataset human activity recognition har dataset built recording volunteer aged 19–48 year performing several daily activity carrying waist-mounted smartphone embedded accelerometer gyroscope objective classify human physical activity one six activity performed study selected two activity sitting standing represent two-class problem included record standing ground-truth sitting ground-truth outcome dataset expanded consider multiple class separate experiment totaling record adding lying walking horizontally walking downstairs walking upstairs record represented 561-dimensional feature vector triaxial acceleration accelerometer estimated body acceleration triaxial angular velocity gyroscope accelerometer gyroscope record pre-processed applying noise filter sampled fixed width sliding window 2.56 overlap window vector feature obtained calculating variable time frequency domain considered time-series binary problem since record feature dimension large dataset naturally clean validation accuracy exceeding binary problem 6-class problem evaluate ldc approach dataset approximately synthetic error introduced class arbitrarily switching label record one class class corresponded approximately flipped label record-based dataset patient care dataset contained variety patient laboratory test result hematocrit erythrocyte many others well key demographic including patient age gender information record used determine whether patient potentially allocated inpatient outpatient treatment hospital forming two target label binary classification problem dataset contained patient record record labeled inpatient another labeled outpatient hospital care record represented attribute problem considered inherently difficult compared har problem since total accuracy approximately obtained validation dataset data split training validation datasets ratio versus respectively original dataset divided two set training validation set record inpatient outpatient used ldc algorithm hold-out test set record inpatient outpatient treated original uncleaned blind test set cleansed training dataset ldc application made available several subsequent model training run validated cleansed validation set total cleansed dataset also uncleansed blind test set result collected compared model trained prior ldc image-based dataset oocyte image dataset contained static image human egg oocyte denuded cumulus cell imaged immediately prior process known intracytoplasmic sperm injection icsi image provided consecutive patient treated single vitro fertilization ivf clinic—california fertility partner image contained single oocyte linked outcome associated embryo development post-fertilization outcome recorded embryologist data collection phase experiment indicated whether fertilized oocyte developed blastocyst specific stage embryo development day ivf 40.9 oocyte developed blastocyst labeled competent oocyte labeled incompetent prior removal record associated error validation set image specified oocyte 40.2 developed blastocyst ivf competent develop blastocyst ivf incompetent representing almost identical class ratio whole dataset addition outcome label record also included associated metadata data entry also specified whether male infertility factor identified treatment image associated treatment involving male infertility factor 37.4 image infertility factor associated 62.6 udc ldc method applied image without male infertility factor using 19.9 cleansing threshold several subsequent model trained validated resulting cleansed dataset consisting image experimental result compared using evaluation metric total accuracy sensitivity specificity udc ldc method model prior data cleansing technique final dataset included training image validation set image ethic approval oocyte image dataset collected prospectively non-interventional study study approved ovation research ethic committee newport beach 92,663 usa accession number of210913b result section one-dimensional convolutional neural network model 1d-cnn -based architecture developed use record-based datasets employed label-clustering deep learning method data cleansing label-noise confidence algorithm section compared result without cleansing convolutional neural network model originally developed image classification problem however customized one-dimensional sequence data shown datasets model learn extract feature sequence observation map internal feature different class label benefit using 1d-cnn layer record-based classification learn raw feature data directly hence require domain expertise manually engineer input feature study label-clustering-based approach ldc validated two contrasting record-based binary classification problem firstly har accelerometer time-series dataset considered two class selected analysis—sitting standing dataset considered good quality high proportion correct label resulting validation accuracy exceeding secondly patient care record-based dataset also considered two class inpatient outpatient dataset contained higher degree label noise considered hard problem absence viable data cleansing method datasets described dataset composition setting section finally label-clustering applied image-based classification problem—a set denuded human oocyte image taken prior icsi also binary classification problem two class defined whether fertilized oocyte developed embryo blastocyst not—these labeled competent incompetent respectively technical aspect underpinning experiment presented accordingly comparing label-clustering different approach human activity recognition comparing consensus approach binary classification ldc used cleanse version har dataset synthetic error intentionally injected flipping approximately label class injection synthetic error allowed ground truth label tracked detection error ldc could quantitated order calculate iou score error identification accuracy noise error dataset typically deteriorate model training process reduce accuracy therefore increase accuracy error removed ldc also used measure data cleansing performance begin process model trained consisting network architecture namely single input branch mlp two fully connected layer size three input branch mlp input branch characterized activation function sigmoid tanh relu function two fully connected layer size 1d-cnn channel kernel size fully connected layer size 30. fivefold cross validation performed architecture described experiment design section best epoch chosen model validation set according log loss preferred evaluation metric illustration 1d-cnn record classification shown fig noted setting number cnn layer zero 1d-cnn practically turn mlp figure illustration record-based classification model denotes full-connected neural network layer softmax denotes layer applies softmax function output final layer technical detail architecture described section experiment design architecture used har patient care record-based classification problem full size image figure compare histogram output record analyzed ldc udc original consensus-based approach data cleansing udc histogram produced aggregating number model incorrectly predicted label datapoint figure show udc histogram result model fig show result top-performing model number bin within two histogram constrained number model voting datapoint udc histogram fig interpreted follows datapoints misclassified comparatively high number contrasting model considered likely mislabeled number model reaching consensus datapoint mislabeled taken score represented -axis two figure datapoint corresponds moderate score e.g 7–8 case considered likely noisy data meaning unclear mislabeled datapoints low consensus mislabeled retained training note cleansing threshold number model needed considered mislabeled noisy adjusted change bin-width histogram lower threshold capture mislabeled noisy data however also mistakenly identify correct data mislabeled noisy tradeoff captured inherently definition iou error identification accuracy—see experiment design section setting cleansing threshold discussed futher figure histogram comparison har dataset injected error various bin size sitting standing class associated binary classification problem udc using model ldc using model udc using top-performing model based log loss ldc using top-performing model based log loss full size image figure show equivalent ldc histogram produced introducing label-clustering note x-axis probabilistic continuous score binned desired level precision rather constrained number model voting datapoint label-noise confidence score range confident label least confident label interpreted similarly udc histogram high moderately high label-noise score indicating data likely mislabeled noisy respectively using model shape udc ldc histogram superficially similar however important note bin size label-noise confidence score arbitrarily made finer using ldc method allowing precise threshold noise tolerance selected especially apparent considering top model fig versus finely grained shape resolved case label-clustering result fig allowing precise identification error use top-performing model led cleaner histogram shape case indicating improved accuracy identifying error consistent excluding poorly performing model would otherwise compromised ability error detection note order produce finer histogram udc consensus approach model would required training cost would therefore increase accordingly ldc method hand able generate finer histogram fewer model reducing training burden maintaining improved precision selecting cleansing threshold figure show iou score changed respect cleansing threshold chosen based percentage datapoints removed udc ldc log loss used metric evaluating best epoch model fig top-performing model fig noise level dataset removing conservative percentage record e.g reduced iou udc ldc similarly aggressively removing record rate also reduced iou udc ldc practice amount noise known advance cleansing threshold obtained heuristically using corresponding histogram figure iou score associated udc ldc har dataset injected error iou score compared different cleansing threshold associated percentage datapoints removed using log loss metric evaluating best epoch model iou score compared different metric evaluating best epoch model fixed cleansing threshold 28.2 iou score compared different cleansing threshold using log loss evaluation metric top-performing model iou score compared different evaluation metric top-performing model fixed cleansing threshold 28.2 full size image figure show iou score changed respect metric used evaluate best epoch model fixed cleansing threshold 28.2 used similar amount injected error model fig top-performing model fig result showed use top-performing model sensitive choice metric due clean shape histogram presented fig however log loss outperformed evaluation metric worse-performing model included generating histogram iou score reached maximum value ldc udc however worth noting iou score underestimate performance cleansing procedure since penalizes removal correct record retaining error extent see experiment design section large datasets removal correct record generally doe hamper performance way presence error therefore error identification accuracy eia measure instead used evaluate percentage record correctly identified error removed defined experiment design section fixed cleansing threshold 28.2 accuracy udc ldc identifying error shown fig maximum performance udc model 80.8 using log loss metric eia increased 82.9 using top-performing model ldc however completely deterministic continuous scale leading reliable precise method identifying error efficiently model needed reduced computing cost performance ldc using top-performing model therefore even higher 84.9 figure comparison error identification accuracy udc ldc har dataset injected error using model top-performing model using range metric evaluating best epoch model score total accuracy balanced accuracy tangent score area receiver operating curve roc-auc log loss ldc applied single model must exclude validation set used select best epoch full size image choice many hyperparameter option selected thus many model used contribute application udc ldc tradeoff computational resource robustness determination confidence data mislabeled noisy given new problem model generally selected highest performing model available interestingly ldc even applied single model representing model measurement score self-consistency noting validation set used select best epoch must excluded since -fold cross validation used single model label-clustering self-consistency single model dataset could still achieve error identification accuracy 82.3 compute resource reduction compared 15-model udc approach far ldc method applied binary classification problem typically har analysis requires two category real-world use ldc method may extended consider multi-class classification manner previously explored udc consensus approach comparing consensus approach multi-class classification ldc method applied multiple class demonstrated extended har dataset class described time-series dataset section similar binary case noise injected dataset changing label dataset randomly-selected class figure present histogram associated label-noise confidence score datapoint divided ground-truth label class contain high proportion clearly labeled clearly mislabeled data e.g lying others contain greater proportion noisy ambiguous data sitting regardless using log loss total accuracy metric selecting best epoch constituent model ldc always achieves higher iou eia score least 0.84 0.89 eia score using total accuracy 0.71 0.81 iou score using log loss shown fig figure show increase total accuracy 64.5 97.2 representing 50.7 improvement model trained ldc-cleansed dataset maximum improvement sitting class representing 60.7 improvement figure model comparison har multi-class dataset injected error multi-class problem ldc histogram iou eia score compared different cleansing method using log loss accuracy metric evaluating best epoch model validation result multi-class har dataset error injected compared training model noisy dataset ldc training model ldc cleaned dataset full size image comparing robust loss function approach binary multi-class classification section comparison made ldc state-of-the-art approach namely generalized cross entropy noise-robust loss function gen seen generalization mean absolute value categorial cross entropy loss another symmetric cross entropy function sym boost cross entropy loss symmetrically counterpart reverse cross entropy maintain fair comparison gen sym method reported cleansed test set account whole original har dataset prior noise injection training set injected noise way comparing consensus approach binary classification section model parameter experimental setting kept consistent model trained post-ldc ldc take intermediate step remove mislabeled highly noisy sample performing post-ldc training cleansed training set method purported robust noise without requiring data cleansing step table present total accuracy har binary multi-class problem different approach best accuracy epoch reported test set last epoch accuracy shown order compare model performance robustness overfitting binary har problem ldc reported minimum 10.2 improvement compared novel loss function sym seemingly volatile gen since model based sym attained higher best accuracy deteriorated sharply training resulting much lower last accuracy multi-class har problem similar trend observed difference accuracy using data cleansing 0.2–6.3 improvement table comparing performance metric different approach binary har multi-class har classification problem using two scenario best accuracy overall corresponding last epoch accuracy model full size table application ldc har patient care section ldc method applied remove error har datasets comprising injected error patient care dataset contained inherent error resulting model trained ldc cleansed datasets evaluated performance improvement compared model trained uncleansed datasets histogram har dataset following ldc shown fig cleansing threshold 28.2 applied training patient care dataset considered hard problem high proportion label error case synthetic label change used dataset contains realistic error arisen naturally data collection model used applying ldc dataset resulting histogram inpatient outpatient shown fig general choice cleansing threshold tradeoff highly problem-dependent aggressively one willing cleanse dataset depend ease problem perspective amount data available cleanse doe fall reasonable amount required train model general rule threshold obtained heuristically assessing range different threshold maximizing value iou score eia described comparing consensus approach binary classification comparing consensus approach multi class classification section figure label-noise confidence score histogram patient care dataset inpatient outpatient class binary classification problem using bin case full size image ldc sample inpatient outpatient equivalent 30.0 dataset identified erroneous mislabeled removed mislabeled record received label-noise confidence score greater 99.99 left 3,089 record training inpatient outpatient inpatient outpatient uncleansed image held back noisy test set confirm data identified removal using ldc approach represent predominantly mislabeled data rather merely hard-to-classify edge case histogram fig show peak associated high level label-noise confidence score indicating high level agreement among ldc contributing model data consistent opposite class shed light apparent mislabeling distribution binary har patient care datasets removal sample identified ldc visualized using principal component analysis pca figure show 2-d map generated first two pca component applied model score figure demonstrates error contaminated cluster sample corresponding two class har dataset sitting standing figure show cleanly class separated ldc equivalent comparison patient care dataset shown fig separation two class inpatient outpatient distinct clearly indicating difficulty classification problem model described experiment design section figure 2-d map generated first two component pca applied model score used input binary har dataset injected error plotted prior removal sample identified using ldc 28.2 threshold black sample correspond sitting red sample correspond standing har dataset plotted removal sample identified using ldc patient care dataset plotted prior ldc sample removal 30.0 threshold black sample correspond inpatient red sample correspond outpatient patient care dataset plotted removal sample identified using ldc full size image figure show performance model trained two datasets measured using total accuracy class accuracy corresponding improvement demonstrated ldc dataset three model trained performance class averaged case har dataset fig show accuracy improvement 68.6 99.2 representing sizeable improvement 44.5 sitting class accuracy lower standing class accuracy prior ldc improvement significant indicating ldc successfully identified error sitting class result similar final accuracy 99.4 standing 99.0 sitting demonstrates ldc indeed removing erroneous data hence improving quality training data figure average performance three model trained prior ldc applied measured using total accuracy class-wise accuracy respective improvement model trained without ldc applied result har dataset error injected shown corresponding result patient care validation dataset shown result patient care blind test set shown model pre- post-ldc applied uncleansed real world version test set full size image figure show increase total accuracy 78.0 98.6 patient care validation dataset representing 26.5 improvement model trained ldc-cleansed dataset similar har dataset one class performed poorly inpatient also exhibited greater improvement 32.8 final class accuracy ldc applied therefore also similar 98.9 outpatient 98.1 inpatient validation dataset indicated sizeable uplift performance model trained using ldc definition cleansed dataset also important quote accuracy model applied uncleansed blind test set representative real-world clinical setting inherent error contained data interestingly accuracy result uncleansed test set similar without ldc applied fig even though result cleansed validation dataset fig showed performance improved using ldc observation highlight challenging define true performance model measured blind test set taken real-world clinical setting inherent error exist accuracy truly measured using error-free dataset reason took predominantly clean har dataset injected known error test performance ldc removing error application ldc labeled oocyte image section denuded human oocyte image dataset taken input udc/ldc algorithm building recent result prototype oocyte assessment model image labeled based whether oocyte upon ivf using icsi developed blastocyst stage key marker oocyte competence inherent label error associated dataset emerge confounding biological factor male infertility affect blastocyst development e.g abnormal sperm morphology motility detail oocyte image dataset presented dataset composition setting section network architecture used ldc process image classification problem described experiment design section figure present workflow process predicting identifying oocyte image incompetent competent develop robust prediction algorithm image preprocessing step essential prior training deep learning classification model first oocyte image underwent pre-processing using trained region based deep convolutional neural network faster r-cnn obtain bounding box oocyte image cropped bounding box optionally feeding image segmentation model especially trained oocyte image using u-net architecture resnet-50 encoder similar manner embryo viability classification pgt-a classification problem segmented image contained mask either intrazonal cavity izc zona pellucida region background see fig third panel model trained input denoted izc model zona model respectively figure workflow pre-processing training model image-based oocyte classification problem image run trained faster r-cnn model obtain bounding box cropping bounding box image optionally segmented using u-net model resnet-50 encoder masking either intrazonal cavity zona pellucida background region binary classification model trained given labeled dataset based range architecture hyperparameter value full size image pre-processing range deep learning architecture hyperparameter value used train binary classification model labeled set oocyte image dataset curated using ldc process result ldc compared using oocyte dataset defined dataset composition setting section outcome label defined whether oocyte developed blastocyst naïve application range deep learning model binary classification training without udc ldc led total accuracy 61.8 reported average performance using 5-fold cross validation validation set containing image using architecture summarized experiment design section removal image linked male infertility factor validation dataset resulted improvement beyond baseline accuracy 63.2 fig correspondingly performance model data containing image associated male infertility factor dropped 59.2 male infertility factor thus confirmed confounding biological variable dataset hinder development blastocyst case otherwise ideal oocyte quality figure comparison model performance term total accuracy class-wise accuracy identifying oocyte lead blastocyst incompetent oocyte lead blastocyst competent result prior removal confounding factor prior udc/ldc shown test set image similar class ratio full dataset result quoted subset dataset contain image male infertility factor contain image male infertility factor respectively cleansing using udc mean performance subsequently trained model shown three kind segmentation pre-processing average result corresponding result data cleansing using ldc full size image proportion error dataset appeared relatively high evidenced model incorrectly classifying 36.8–38.2 validation image average train model appropriately erroneously learn high-quality oocyte lead blastocyst necessary remove mislabeled record training set application udc ldc independently identified 31.6 known male infertility case mislabeled result suggest cleansing method correctly identifying male infertility factor major source error evaluating oocyte competency hence record associated male infertility factor removed prior applying udc ldc algorithm training accounted 37.4 dataset consensus-based udc approach applied remaining image remove another 19.9 likely mislabeled noisy data remaining cleansed dataset consisted image anticipated high quality label suitable training note case blind test set available due insufficient initial dataset size similar procedure followed using label-clustering ldc applying udc ldc subsequently trained model divided three category without segmentation pre-processing zona model izc model see fig performance model shown fig ldc udc respectively result average least two model-training run three different deep learning architecture across segmentation type average uplift 18.4 total accuracy observed ldc model 61.8 73.1 pre- post-ldc model respectively furthermore ldc model showed average improvement 2.2 udc model poorest performing segmented model izc model occlude zona pellucida region conversely unsegmented image performed best average uplift 25.5 total accuracy 77.5 discussion increasingly efficient algorithm accurate automated identification error data aid development robust scalable model particularly significant medical datasets inherently poor quality subjectivity complex biological confounding variable data privacy consideration make manual identification unfeasible novel approach combining deep learning label-clustering ldc demonstrated vastly improved computational efficiency fewer resource required compared udc method model-consensus-driven approach time ldc approach retained ability identify error datasets priori self-consistency alone rather pre-training specific instance known error method demonstrated improved scalability reduced complexity data management compared required build consensus-based histogram replacing continuous label-noise confidence score ability identify error maintained improved accuracy model trained using cleansed dataset based human activity recognition originally containing manually-injected error exhibited greater stability training model trained uncleansed dataset loss function training remains flatter minimized oscillation occur training noise injected model also demonstrated uplift total accuracy introduction continuous label-noise confidence score based label-clustering allows precision removing error dataset given threshold tolerance subsequent development higher performing model extending multi-class problem even greater accuracy uplift measured using data cleansing method—up 64.5 improvement interestingly result compared existing method handling noise namely two choice robust loss function handling data error ldc method showed least improvement binary classification comparable slightly increased improvement multi-class classification might indicate multi-class problem amenable method handling error since greater choice class error distributed accumulation error binary classification problem hence likely severe error conspire appear systematic i.e look like rule difficult prevent learning ldc applied dataset patient care record high proportion inherent error demonstrated ability cleanly separate class inpatient outpatient illustrated 2-d map based pca analysis removing high proportion suspected error trained model performance approached compared prior cleansing also highlighted challenge testing performance poor-quality dataset encountered real-world clinical setting misleading true performance model better performing model show little accuracy improvement applied datasets error turning attention medical imaging dataset denuded human oocyte labeled outcome based blastocyst formation cleansing able identify 31.6 mislabeled image associated male infertility factors—a significantly confounding variable correctly identifying high quality oocyte fertilization ivf applying ldc deep learning model binary classification several kind segmented oocyte image input led significant uplift performance predicting oocyte competence 61.8 73.1 average—a 18.4 increase performance increase oocyte classification dependent segmentation style model trained unsegmented image exhibited total accuracy performance 77.5 greater intrazonal cavity izc segmented image 71.7 zona pellucida segmented image 70.1 observation suggest could synergistic effect interplay izc quality zona pellucida evaluating oocyte competence predictive power one alone reduced historical literature support view zona pellucida morphology significant indicator oocyte quality noted masking component image reduces overall predictive power may indicate value ensembling distilling model trained segmented unsegmented image result indicate automating detection error datasets made scalable robust without human oversight would violate data privacy given growing cost manual data verification cleansing increasingly big data around world paper provides pivotal framework automated algorithm detect data error beyond application