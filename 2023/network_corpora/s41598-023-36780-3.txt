introduction massive uptake development deployment large-scale natural language generation nlg system recent month yielded almost unprecedented worldwide discussion future society chatgpt service serf web front-end gpt-3.5 gpt-4 fastest-growing service history break million user milestone january billion visit february driven upheaval particularly anticipated education knowledge transfer future generation conduct first independent systematic study ai-generated language content typically dealt high-school education argumentative essay i.e essay student discus position controversial topic collecting reflecting evidence e.g student taught cooperate compete learning write essay crucial aspect education student learn systematically ass reflect problem different perspective understanding capability generative perform task increase understanding skill model well challenge educator face come teaching crucial skill multitude individual example anecdotal evidence quality ai-generated content genre e.g paper first systematically ass quality human-written ai-generated argumentative text across different version chatgpt use fine-grained essay quality scoring rubric based content language mastery employ significant pool domain expert i.e high school teacher across discipline perform evaluation using computational linguistic method rigorous statistical analysis arrive several key finding model generate significantly higher-quality argumentative essay user essay-writing online forum frequented german high-school student across criterion scoring rubric chatgpt-4 chatgpt web interface gpt-4 model significantly outperforms chatgpt-3 chatgpt web interface gpt-3.5 default model respect logical structure language complexity vocabulary richness text linking writing style human generative model differ significantly instance gpt model use nominalizations higher sentence complexity signaling complex scientific language whereas student make use modal epistemic construction tend convey speaker attitude linguistic diversity nlg model seems improving time chatgpt-3 still significantly lower linguistic diversity human chatgpt-4 significantly higher diversity student work significantly beyond existing benchmark openai technical report gpt-4 present benchmark evaluation lack scientific rigor fails provide vital information like agreement raters doe report detail regarding criterion assessment extent statistical analysis conducted larger sample essay contrast benchmark provides first statistically rigorous systematic study essay quality paired computational linguistic analysis language employed human two different version chatgpt offering glance nlg model develop time work focused argumentative essay education genre also relevant beyond education general studying argumentative essay one important aspect understand good generative model conveying argument consequently persuasive writing general related work natural language generation recent interest generative model largely attributed public release chatgpt public interface form interactive chat based instructgpt model commonly referred gpt-3.5 comparison original gpt-3 similar generative large language model based transformer architecture like gpt-j model trained purely self-supervised manner e.g masked language modeling instead pipeline involved human-written content used fine-tune model improve quality output mitigate bias safety issue well make generated text similar text written human model referred fine-tuned language net flan detail training refer literature notably process recently reproduced publicly available model alpaca dolly i.e complete model downloaded accessed api however assume similar process used training gpt-4 since paper openai doe include detail model training testing language competency large-scale nlg system recently started cai show chatgpt reuses sentence structure access intended meaning ambiguous word identifies thematic structure verb argument replicating human language use mahowald compare chatgpt acceptability judgment human judgment article adjective numeral noun construction english dentella show chatgpt-3 fails understand low-frequent grammatical construction like complex nested hierarchy self-embeddings another recent line research structure automatically generated language evaluated guo show question-answer scenario chatgpt-3 different linguistic device human zhao show chatgpt generates longer diverse response user apparently negative emotional state given aim identify certain linguistic characteristic human-written versus ai-generated content also draw related work field linguistic fingerprinting assumes human unique way using language express i.e linguistic mean employed communicate thought opinion idea differ human property identified computational linguistic mean showcased across different task computation linguistic fingerprint allows distinguish author literary work identification speaker profile large public debate provision data forensic voice comparison broadcast debate educational purpose linguistic feature used measure essay readability essay cohesion language performance score essay grading integrating linguistic fingerprint also yield performance advantage classification task instance predicting user opinion identifying individual user limitation openais chatgpt evaluation openai published discussion model performance several task including advanced placement class within educational system subject used performance evaluation diverse include art history english literature calculus statistic physic chemistry economics politics model achieved good good mark subject perform well english literature gpt-3.5 also experienced problem chemistry macroeconomics physic statistic overall result impressive several significant issue firstly conflict interest model owner pose problem performance interpretation secondly issue soundness assessment beyond conflict interest make generalizability result hard ass respect model capability write essay notably exam combine multiple-choice question free-text answer aggregated score publicly available best knowledge neither generated free-text answer overall assessment assessment given specific criterion used judgment rubric published thirdly paper state 1–2 qualified third-party contractor participated rating free-text answer unclear often multiple rating generated answer agreement lack information hinders scientifically sound judgement regarding capability model general also specifically essay lastly owner model conducted study few-shot prompt setting gave model structured template well example human-written high-quality essay guide generation answer fine-tuning model generate could also influenced output result published owner beyond course directly comparable work also consider student assessment like graduate record examination gres however evaluation suffer problem scientific rigor class scientific assessment chatgpt researcher across globe currently assessing individual capability model greater scientific rigor note due recency speed development hereafter discussed literature mostly published pre-prints yet peer-reviewed addition issue concretely related assessment capability generate student essay also worth noting likely large problem trustworthiness evaluation data contamination i.e benchmark task part training model enables memorization example aiyappa find evidence likely case benchmark result regarding nlp task complicates effort researcher ass capability model beyond memorization nevertheless first assessment result already available though mostly focused chatgpt-3 yet chatgpt-4 closest work study yeadon also investigate chatgpt-3 performance writing essay grade essay generated chatgpt-3 five physic question based criterion cover academic content appreciation underlying physic grasp subject material addressing topic writing style question ten essay generated rated independently five researcher sample size precludes statistical assessment result demonstrate model capable writing high-quality physic essay quality varies manner similar human-written essay guo create set free-text question answering task based data collected internet e.g question answering reddit author sample thirty triplet question human answer chatgpt-3 generated answer ask human raters ass detect written human written approach doe directly ass quality output serf turing test designed evaluate whether human distinguish human- ai-produced output result indicate human fact able distinguish output presented pair answer human familiar chatgpt also able identify ai-generated answer without seeing human answer comparison however human yet familiar chatgpt-3 capable identifying ai-written answer time moreover author also find ai-generated output deemed helpful human answer slightly half case suggests strong result openai benchmark regarding capability generate free-text answer generalize beyond benchmark however indicator benchmark may overly optimistic assessment model capability example kortemeyer conduct case study ass well chatgpt-3 would perform physic class simulating task student need complete part course answer multiple-choice question homework assignment ask question lesson complete programming exercise write exam free-text question notably chatgpt-3 allowed interact instructor many task allowing multiple attempt well feedback preliminary solution experiment show chatgpt-3 performance many aspect similar beginning learner model make similar mistake omitting unit simply plugging result equation overall would passed course low score 1.5 4.0 similarly kung study performance chatgpt-3 united state medical licensing exam usmle find model performs near passing threshold assessment bit optimistic kortemeyer state level performance comprehensible reasoning valid clinical insight suggest model chatgpt may potentially assist human learning clinical decision making frieder evaluate capability chatgpt-3 solving graduate-level mathematical task find chatgpt-3 seems mathematical understanding level well average student case sufficient pas exam yuan consider arithmetic ability language model including chatgpt-3 chatgpt-4 find exhibit best performance among currently available language model incl llama flan-t5 bloom however accuracy basic arithmetic task still considering correctness degree 10^ i.e model still capable functioning reliably calculator slightly satiric yet insightful take spencer ass scientific paper gamma-ray astrophysics would look like written largely assistance chatgpt-3 find language capability good model capable generating equation argument often flawed reference scientific literature full hallucination general reasoning skill model may also level expected benchmark example cherian evaluate well chatgpt-3 performs eleven puzzle second grader able solve find chatgpt able solve average 36.4 attempt whereas second grader achieve mean 60.4 however sample size small problem posed multiple-choice question answering problem directly compared nlg consider research gap within article address important part current research gap regarding capability chatgpt similar technology guided following research question rq1 good chatgpt based gpt-3 gpt-4 writing argumentative student essay rq2 ai-generated essay compare essay written student rq3 linguistic device characteristic student versus ai-generated content study aspect help large group teaching professional systematically ass large corpus student essay best knowledge first large-scale independent scientific assessment chatgpt similar model kind answering question crucial understanding impact chatgpt future education material method data essay topic originate corpus argumentative essay field argument mining argumentative essay require student think critically topic use evidence establish position topic concise manner corpus feature essay topic essay forum active community providing writing feedback different kind text frequented high-school student get feedback native speaker essay-writing capability information age writer available topic indicate essay written grade 11–13 indicating author likely least topic range student taught cooperate compete newspaper become thing past corpus topic feature one human-written essay uploaded discussed forum student wrote essay native speaker average length essay sentence token average 2.089 character termed student essay remainder paper present study use topic stab gurevych prompt chatgpt write essay word topic receive automatically-generated essay chatgpt-3 chatgpt-4 version march chatgpt-3 essay chatgpt-4 essay additional prompt getting response used i.e data created basic prompt zero-shot scenario contrast benchmark openai used engineered prompt few-shot scenario guide generation essay note decided ask word noticed tendency generate essay longer desired length chatgpt prompt asking word typically yielded essay word thus using shorter length prevent potential advantage chatgpt longer essay instead err side brevity similar evaluation free-text answer openai consider multiple configuration model due effort required obtain human judgment reason data restricted chatgpt doe include model available time e.g alpaca use browser version tool consider realistic scenario using api table show core statistic resulting dataset supplemental material show example essay data set table core statistic dataset full size table annotation study study participant participant registered two-hour online training entitled chatgpt challenge opportunity conducted author paper mean provide teacher technological background nlg system general chatgpt particular teacher permanently employed secondary school allowed register training focusing expert alone allows receive meaningful result participant wide range experience assessing student writing total teacher registered training teach grammar school teacher hold position secondary school half registered teacher teacher service many year successfully applied promotion data protection reason know subject combination registered teacher know variety subject represented including language english french german religion/ethics science supplemental material provides general information regarding german teacher qualification training began online lecture followed discussion phase teacher given overview language model basic information chatgpt developed minute teacher received written oral explanation questionnaire core study see supplementary material informed minute finish study task explanation included information data obtained collect self-assessment chose criterion rating essay overall goal research walk-through questionnaire participation questionnaire voluntary affect awarding training certificate informed participant data collected anonymously would way identifying participated questionnaire orally informed participant consent use provided rating research participating survey instruction provided orally writing link online form given participant online form running local server log information could identify participant e.g address ensure anonymity per instruction consent participation given using online form due full anonymity could definition document exactly provided consent implemented insurance non-participation could possibly affect awarded training certificate training participant take part questionnaire study remaining participant consented based information provided participated rating essay questionnaire continued online lecture opportunity using chatgpt teaching well beyond chatbots study protocol reviewed approved research ethic committee university passau confirm study protocol accordance relevant guideline questionnaire questionnaire consists three part first brief self-assessment regarding english skill participant based common european framework reference language cefr six level ranging comparable native speaker basic skill see supplementary material participant shown six essay participant shown generated text provided information whether text human-written ai-generated questionnaire cover seven category relevant essay assessment shown detail see supplementary material topic completeness logic composition expressiveness comprehensiveness language mastery complexity vocabulary text linking language construct category used guideline essay assessment established ministry education lower saxony germany criterion seven-point likert scale score zero six defined zero worst score e.g relation topic six best score e.g addressed topic special degree questionnaire included written description guidance scoring rating essay participant also asked self-assess confidence rating used five-point likert scale based criterion self-assessment peer-review score association computational linguistics acl participant finished rating six essay shown summary rating well individual rating essay information essay generated computational linguistic analysis order explore compare quality essay written student chatgpt consider six following linguistic characteristic lexical diversity sentence complexity nominalization presence modal epistemic discourse marker motivated previous work wei observe correlation measure lexical syntactic discourse complexity essay grading german high-school examination mcnamara explore cohesion indicated among thing connective syntactic complexity lexical diversity relation essay scoring lexical diversity identify vocabulary richness using well-established measure textual lexical diversity mtld often used field automated essay grading take account number unique word unlike best-known measure lexical diversity type-token ratio ttr sensitive difference length text fact koizumi nami find least affected difference length text compared measure lexical diversity relevant due difference average length human-written chatgpt-generated essay syntactic complexity use two measure order evaluate syntactic complexity essay one based maximum depth sentence dependency tree produced using spacy 3.4.2 dependency parser syntactic complexity depth second measure adopt approach similar nature one wei use clause structure evaluate syntactic complexity case count number conjuncts clausal modifier noun adverbial clause modifier clausal complement clausal subject parataxes syntactic complexity clause supplementary material show difference sentence complexity based two example data nominalization common feature scientific style writing used additional measure syntactic complexity order explore feature count occurrence noun suffix -ion -ment -ance others known transform verb noun semantic property modal epistemic marker signal commitment writer statement identify modal using pos-tagging module provided spacy well list epistemic expression modality definitely potentially also used approach identifying semantic property epistemic marker adopt empirically-driven approach utilize epistemic marker identified corpus dialogical argumentation hautli-janisz consider expression think believed opinion epistemic discourse property discourse marker used measure coherence quality text explored somasundaran use discourse marker evaluate story-telling aspect student writing nadeem incorporated deep learning-based approach automated essay scoring present paper employ pdtb list discourse marker adjust exclude word often used purpose indicating discourse relation like etc statistical method use within-subjects design study participant shown six randomly selected essay result submitted survey system essay completed case participant ran time finish scoring six essay cronbach allows determine inter-rater reliability rating criterion data source human chatgpt-3 chatgpt-4 order understand reliability data overall also data source rating criterion use two-sided wilcoxon-rank-sum test confirm significance difference data source criterion use test determine significance linguistic characteristic result three comparison human vs. chatgpt-3 human vs. chatgpt-4 chatgpt-3 vs. chatgpt-4 seven rating criterion seven linguistic characteristic i.e test use holm-bonferroni method correction multiple test achieve family-wise error rate 0.05 report effect size using cohen data perfectly normal also doe severe outlier prefer clear interpretation cohen slightly appropriate accessible non-parametric effect size measure report point plot estimate mean score data source criterion incl confidence interval mean value confidence interval estimated non-parametric manner based bootstrap sampling visualize distribution criterion using violin plot provide visual indicator spread data see supplementary material use self-assessment english skill confidence essay rating confounding variable determine rating affected language skill confidence instead actual quality essay control impact measuring pearson correlation coefficient self-assessments rating also determine whether linguistic feature correlated rating expected sentence complexity tree depth dependency clause well nominalization indicator complexity language similarly use discourse marker signal proper logical structure finally large lexical diversity correlated rating vocabulary measure pearson use two-sided test significance based -distribution model expected correlation implemented scipy use holm-bonferroni method account multiple test however note likely all—even tiny—correlations significant given amount data consequently interpretation result focus strength correlation statistical analysis data implemented python use panda 1.5.3 numpy 1.24.2 processing data pingouin 0.5.3 calculation cronbach scipy 1.10.1 wilcoxon-rank-sum test pearson seaborn 0.12.2 generation plot incl calculation error bar visualize confidence interval result table arithmetic mean standard deviation cronbach rating full size table table arithmetic mean standard deviation linguistic marker full size table table p-values wilcoxon signed-rank test adjusted multiple comparison using holm-bonferroni method effect size measured cohen reported significant result full size table teacher completed questionnaire rated six essay one rated five essay one rated two essay one rated one essay result rating essay topic essay type human- chatgpt-3- chatgpt-4-generated three rating essay two rating essay one rating five essay inter-rater agreement consistently excellent 0.9\ exception language mastery good agreement =0.89\ see table correlation analysis depicted supplementary material show weak positive correlation 0.11 0.28 self-assessment english skill respectively self-assessment confidence rating actual rating overall indicates rating reliable estimate actual quality essay potential small tendency confidence rating language skill yield better rating independent data source table supplementary material characterize distribution rating essay grouped data source observe criterion clear order mean value student worst rating chatgpt-3 middle rank chatgpt-4 best performance observe standard deviation fairly consistent slightly larger one i.e spread similar rating essay supported visual analysis violin plot statistical analysis rating reported table show difference human-written essay one generated chatgpt model significant effect size human versus chatgpt-3 essay 0.52 1.15 i.e medium 0.5,0.8 large 0.8 1.2 effect one hand smallest effect observed expressiveness complexity i.e come overall comprehensiveness complexity sentence structure difference human chatgpt-3 model smallest hand difference language mastery larger difference indicates human prone making mistake writing nlg model magnitude difference human chatgpt-4 larger effect size 0.88 1.43 i.e. large large 1.2 effect chatgpt-3 difference smallest expressiveness complexity largest language mastery please note difference language mastery human gpt model doe mean human low score language mastery m=3.90 rather nlg model exceptionally high score m=5.03 chatgpt-3 m=5.25 chatgpt-4 consider difference two gpt model observe chatgpt-4 consistently higher mean value criterion difference logic composition vocabulary text linking complexity significant effect size 0.45 0.5 i.e small 0.2 0.5 medium thus gpt-4 seems improvement gpt-3.5 general clear indicator better clearer logical composition complex writing diverse vocabulary also observe significant difference distribution linguistic characteristic three group see table sentence complexity depth category without significant difference human chatgpt-3 well chatgpt-3 chatgpt-4 also significant difference category discourse marker human chatgpt-3 magnitude effect varies lot 0.39 1.93 i.e. small 0.2 0.5 large however comparison rating clear tendency regarding direction difference instance chatgpt model write complex sentence use nominalizations human tend use modal epistemic marker instead lexical diversity human higher chatgpt-3 lower chatgpt-4 difference use discourse marker human chatgpt-3 chatgpt-4 significantly fewer discourse marker detect expected positive correlation complexity rating linguistic marker sentence complexity r=0.16\ depth r=0.19\ clause nominalizations r=0.22\ however observe negative correlation logic rating discourse marker r=-0.14\ counter intuition frequent use discourse indicator make text logically coherent however line previous work mcnamara also find indication use cohesion index discourse connective correlate high- low-proficiency essay finally observe expected positive correlation rating vocabulary lexical diversity r=0.12\ observed correlation significant however note strength correlation weak significance over-interpreted due large sample size discussion result provide clear answer first two research question consider quality generated essay chatgpt performs well writing argumentative student essay outperforms quality human-written essay significantly chatgpt-4 model least large effect average one point better human seven-point likert scale regarding third research question find significant linguistic difference human ai-generated content ai-generated essay highly structured instance reflected identical beginning concluding section chatgpt essay conclusion ... initial sentence essay also similar starting general statement using main concept essay topic although corresponds general structure sought argumentative essay striking see chatgpt model rigid realizing whereas human-written essay looser representing guideline linguistic surface moreover linguistic fingerprint counter-intuitive property use discourse marker negatively correlated logical coherence believe might due rigid structure generated essay instead using discourse marker model provide clear logical structure separating different argument paragraph thereby reducing need discourse marker data also show hallucination problem setting argumentative essay writing essay topic really factual correctness rather argumentation critical reflection general concept seem contained within knowledge model stochastic nature language generation well-suited kind task different plausible argument seen sampling available argument topic nevertheless need perform systematic study argumentative structure order better understand difference argumentation human-written chatgpt-generated essay content moreover also rule subtle hallucination may overlooked rating also essay low rating criterion related factual correctness indicating might case model still problem even average better student one issue evaluation recent large-language model accounting impact tainted data benchmarking model certainly possible essay sourced stab gurevych internet part training data gpt model proprietary nature model training mean confirm however note generated essay resemble corpus human essay moreover topic essay general sense human able reason write topic understanding concept like cooperation consequently taint general topic i.e fact might present data possible actually expected unproblematic relates capability model learn concept rather memorization specific task solution everything ensure sound construct high validity study still certain issue may affect conclusion importantly neither writer essay raters english native speaker however student purposefully used forum english writing frequented native speaker ensure language content quality essay indicates resulting essay likely average non-native speaker went least one round revision help native speaker teacher informed part training would english prevent registration people without english language skill moreover self-assessment language skill weakly correlated rating indicating threat soundness result low definitively rule result would reproducible human raters high inter-rater agreement indicates unlikely however reliance essay written non-native speaker affect external validity generalizability result certainly possible native speaking student would perform better criterion related language skill though unclear much however language skill particular strength model meaning difference might smaller still reasonable conclude model would least comparable performance human possibly still better performance smaller gap rule difference content-related criterion also see strong argument native speaker better argument non-native speaker thus result might fully translate native speaker see reason aspect regarding content similar result obtained based high-school-level essay native non-native speaker higher education degree expert field would likely also achieve better performance difference performance model human would likely also smaller setting note essay topic may unbiased sample stab gurevych randomly sampled essay writing feedback section essay forum unclear whether essay posted representative general population essay topic nevertheless believe threat fairly low result consistent seem influenced certain topic certainty conclude result generalize beyond chatgpt-3 chatgpt-4 similar model like bard http hl=en alpaca dolly especially result linguistic characteristic hard predict however since—to best knowledge given proprietary nature models—the general approach model work similar trend essay quality hold model comparable size training procedure finally want note current speed progress generative extremely fast studying moving target chatgpt 3.5 today already model studied due lack transparency regarding specific incremental change know predict might affect result conclusion result provide strong indication fear many teaching professional warranted way student homework teacher ass need change world generative model non-native speaker result show student want maximize essay grade could easily relying result model like chatgpt strong performance model indicates might also case native speaker though difference language skill probably smaller however goal education consequently educator need change approach homework instead assigning grading essay need reflect output tool regarding reasoning correctness model need seen integral part education one requires careful reflection training critical thinking skill furthermore teacher need adapt strategy teaching writing skill use calculator necessary critically reflect student use tool instance constructivist argue learning enhanced active design creation unique artifact student present case mean long term educational objective may need adjusted analogous teaching good arithmetic skill younger student allowing encouraging student use calculator freely later stage education similarly sound level literacy achieved strongly integrating model lesson plan may longer run counter reasonable learning goal term shedding light quality structure ai-generated essay paper make important contribution offering independent large-scale statistically sound account essay quality comparing human-written ai-generated text comparing different version chatgpt also offer glance development model time term linguistic property quality exhibit result show language generated chatgpt considered good human also notable structural difference e.g use discourse marker demonstrates in-depth consideration capability generative model required i.e task used also language generate example read many ai-generated text use fewer discourse marker raise question would affect human use discourse marker understanding ai-generated text differ human-written enables look difference reason potential impact study possibly mitigate impact