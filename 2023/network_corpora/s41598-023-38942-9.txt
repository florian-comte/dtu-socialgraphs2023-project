introduction knowledge graph gained increasing popularity last decade science technology enable versatile evolving semantic representation knowledge crossroad various level information structuring unstructured semi-structured structured level abstraction conceptual vs. operational knowledge representation formalism graph fact entity-relationship logic technology ecosystem however publicly available knowledge graph dbpedia wikidata relatively simple moderate semantic structure although vary content size coverage overlap primarily represent collection factual statement arranged entity description possibly enriched class hierarchy corresponding property definition question answering benchmark system far geared primarily towards encyclopedic knowledge graph dbpedia wikidata currently new type knowledge graph called research knowledge graph emerging whose content bibliographic metadata scientific element idea theory approach claim conveyed scholarly contribution omics data structure personalized medicine novel research knowledge graph increasingly intertwine three previously largely isolated aspect semantic representation semantic intelligence machine learning machine intelligence crowd expert sourcing human intelligence particular scholarly communication challenging application domain due heterogeneity knowledge representation concept drift knowledge evolution along scientific discourse different knowledge granularity used describe research contribution novel knowledge structure beyond simple entity description present sciqa scientific benchmark scholarly knowledge benchmark leverage open research knowledge graph orkg http currently comprising almost 170,000 resource describing research contribution almost 15,000 scholarly article research field research contribution contain among thing detail research process method material used specific result figure show concrete example paper budde described orkg paper report four mechanical process manufacturing hybrid solid component fig show part description one four process described orkg overall four description includes detail entire mechanical process concerning individual step sequence per step incoming outgoing component measurement method measurement result figure concrete example paper described orkg blue shape resource predicate orkg schema yellow shape user-generated resource predicate human-readable label class represented blue color resource within orkg shown magenta full size image following bottom-up methodology first manually developed set question answered orkg subsequently devised eight question template automatically generated question also answered orkg handcrafted autogenerated sciqa question cover several research field ranging computer science engineering chemistry geology science technology immunology genetics life science economics urban study social science question cover numerous question type including non-factoid factoid question corresponding sparql query different query shape triple pattern size translated question sparql query orkg provide comprehensive set related ground-truth query result demonstrate applicability feasibility sciqa benchmark presenting two preliminary evaluation targeting handcrafted question first present proof-of-concept implementation scholarly system based jarvisqa system jarvisqa operates exclusively table tabular view knowledge graph autogenerated part sciqa based table tabular view reason evaluation performed handcrafted part sciqa however jarvisqa system able retrieve correct answer subset handcrafted question due diverse data question type sciqa compared data jarvisqa built second present initial insight using large language model llm chatgpt answering handcrafted question evaluation aim understand well one current famous llm able answer complex query scholarly knowledge superlative comparison etc. evaluation also focused hand-crafted question compare result jarvisqa chatgpt preliminary evaluation found system perform rather low best-performing configuration jarvis_ xls2 proof-of-concept implementation jarvisqa able answer question correct answer chatgpt provided answer question answer correct low number substantiate answering question scholarly knowledge challenge current system llm reason conclude sciqa benchmark represents challenging task next-generation system system must also deal scientific knowledge addition encyclopedic knowledge related work problem answering question expressed natural language received lot attention recently depending kind system query e.g. text document knowledge graph relational database image archive benchmark developed evaluating respective system since focus paper scholarly knowledge graph concentrate benchmark knowledge graph linked data overview relevant benchmark presented table table benchmark comparison full comparison available orkg full size table one first datasets uestions contains factoid question-answer pair targeted freebase created using google suggest api obtain question begin -word 100k randomly selected question submitted amazon mechanical turk asking worker annotate one answered freebase term structural complexity uestions simple many question contain one class one property one instance uestions extended uestions providing sparql query question annotator could fully process find answer dataset imple uestions also target freebase created manually english-speaking annotator consists factoid question much larger uestions containing 108,442 simple question paired corresponding answer explanation diefenbach created benchmark imple uestions ikidata converting imple uestions target wikidata lc-quad dataset differs previous one includes simple factoid question also complex one i.e. respective sparql query contain multiple triple pattern dataset contains pair questions-sparql query targeting dbpedia question generated semi-automatically extracting sub-graphs containing triple within 2-hop distance seed entity generation sparql query question facilitated automatically using template refined manually development lc-quad developer proceeded development lc-quad 2.0 contains 30,000 question paraphrase corresponding sparql query lc-quad 2.0 target wikidata dbpedia created similarly lc-quad lc-quad 2.0 also contains question higher complexity non-factoid question question qualifier aggregate temporal aspect qualifier superlative benchmark omplex uestions 34,689 question similar complexity contains composition question superlative comparative generated uestions sampling question-query pair automatically creating complex sparql query query set question generated automatically using template reformulated amazon mechanical turk worker benchmark generated qald challenge http also high complexity qald- benchmark generated testing latest challenge nliwod eswc2022 contains manually created wikidata-based question varied complexity annotated manually specified sparql query output question may contain count superlative comparative temporal aggregator question available different language i.a. english german chinese russian question english collected speaker least c1-level language proficiency accordance common european framework reference language according participant express real-world information need native speaker translated question language benchmark section target either freebase dbpedia wikidata thus mainly encyclopedic knowledge graph sciqa benchmark focus essentially scholarly knowledge major advantage using orkg basis allows generation sophisticated query e.g. superlative comparison scholarly knowledge one presented sciqa benchmark necessary provides relevant evidence advantage enhanced class comparison among research output orkg contains comparison provide condensed overview state-of-the-art particular research question way sciqa includes sophisticated question comparison i.e. aggregation semantic contribution description various scientific paper applicability feasibility evaluation shown sophisticated system llm like chatgpt difficulty answering type question require scholarly knowledge fact handcrafted sciqa question answered correctly system large language model respectively regarding structure sciqa meet current standard benchmark contains natural language question sparql query answer finally also benchmark includes feature sparql query e.g. query shape query component triple pattern size orkg dataset orkg research knowledge graph includes semantic description research article accompanying service http production curation use data structured knowledge orkg contributed i.e. crowdsourced researcher partially also automatically extracted literature integrated resource comprising structured research contribution description figure provides overview core structure orkg paper added orkg contains bibliographic metadata i.e. author title year publication doi research field user-generated semantic description scientific contribution fig show concrete example paper budde described orkg figure basic orkg schema paper blue shape resource predicate orkg schema yellow shape user-generated resource predicate class resource predicate omitted brevity full size image core entity orkg contribution presented form research paper contribution typically linked research field problem description includes several property specific research field problem predefined fixed set property describe research contribution property defined fly curator one hand openness extensibility allow selecting defining appropriate knowledge representation research paper hand hand brings significant challenge potential application based described paper contribution contribution dealing specific research problem scholarly literature compared so-called comparison comparison tabular representation property compared contribution comparison provide overview key information research problem across dozen hundred contribution way comparison valuable tool example determine leading sorting algorithm find dangerous virus compared virus table provides statistic orkg knowledge graph orkg still relatively small compared knowledge graph often include million entity however anticipate novel structure scholarly knowledge orkg already pose challenging task system table overview size orkg knowledge graph based exported rdf dump full size table approach section describe approach creating sciqa benchmark creating benchmark requires collection question covering different aspect scenario knowledge graph contains data particular approach consists two main step manual creation handcrafted question automated generation autogenerated question approach inspired procedure related work also combined use manual question creation automated question generation create sciqa benchmark followed detailed methodology tackle following key aspect objective data structure data collection objective goal benchmark create dataset also provide variety knowledge base scenario i.e. question asked knowledge graph type use case utilize data data structure orkg represents information paper collection contribution figure depicts core schema scholarly data orkg followed query data source data collection performed collection data two main step manual creation automated generation figure illustrates entire approach form activity diagram highlight main activity undertook create sciqa benchmark workflow handcrafted question started first workflow selecting research field corresponding list orkg comparison field limit scope data queried subsequently defined several natural language question according different type e.g. single comparison question true/false question aggregation question min max average etc natural language question created one sparql query two variation human-readable machine-readable question query created collected associated metadata e.g. type query shape etc finally natural language question structured sparql query collected metadata peer-reviewed multiple time syntactic semantic correctness author five country three continent participated workflow accommodate different perspective addition researcher consulted domain expert personal network available ensure question created relevant important respective research field researcher furthermore leveraged expertise domain expert participating orkg curation grant create relevant realistic useful question workflow autogenerated question performed second workflow enrich sciqa benchmark even though handcrafted question purposefully created number question rather small benchmark purpose expanded sciqa benchmark integration set automatically generated question created using structured approach involves combination handcrafted question query utilization llm case gpt-3 objective autogenerated question target specific part orkg creating query placeholder populated various entity thereby facilitating generation numerous natural language question create autogenerated question followed structured process creating handcrafted question observed data orkg heterogeneous complicates automatic generation question query reason decided set certain restriction generation question query first decided focus specific dataset papers-with-code available orkg although dataset belongs one research field computer science extensive paper around total number paper orkg homogeneously described homogeneity important facilitates automatic generation question query second decided focus question query shape tree class which-what type factoid narrow scope automatic generation shape class type common handcrafted question also match nature selected papers-with-code data initially crafted set eight query question query created one question manually three variation using gpt-3 careful manual validation next collected possible entity placeholder query orkg filled query placeholder possible entity selecting one question randomly query finally collected result created query extracted metadata final set question addition autogenerated question expands sciqa dataset total question query providing larger corpus training machine-learning-based question-answering system approach particularly useful compared relying solely handcrafted question often limited number may capture full scope underlying data contrast use machine-generated question provides diverse extensive set question help improve accuracy robustness machine-learning model answering question large knowledge graph figure detailed workflow development generation sciqa benchmark full size image sciqa benchmark section provide overview sciqa question corresponding sparql query first explain classified question extract metadata presenting example handcrafted autogenerated question detail question classification appropriate question typology help satisfy two main goal benchmark development namely extensive coverage different topic various subject area appear knowledge graph validation pattern used writing question query ensure better balanced distribution question across possible different type information requested many existing approach defining taxonomy question type wendy lehnert proposed conceptual taxonomy conceptual class e.g. causal antecedent goal orientation enablement etc roth developed two-layered taxonomy based answer type semantics six coarse class abbreviation entity description human location numeric value fine class subclass different coarse class overlap singhal designed small set simple answer type corresponding question class word expected answer type person location organization date quantity duration linear measure example question start type person system quarc defines question categorization based use certain interrogative pronoun e.g. similar approach used system askbill eleven question type defined question pattern type qtemporalage identified pattern old/at which/what age research data description complex structure semantics developing question search information within data useful define type expected answer focus question definition necessary type expected answer based result evaluation campaign qald analysis characteristic problem associated task mapping natural language formal query presented cimiano minock problem include lexical ambiguity arise one word interpreted different way i.e. refer different entity concept light expression verb preposition either refer ontological property highly underspecified way correspond property lexical gap user vocabulary ontology complex question expressed using query involving aggregation function comparison superlative temporal reasoning definition focus question make search answer specific moldovan defined question focus word sequence word indicate information asked question ferret defined question focus noun phrase likely present answer consisting head noun list modifier example question type nanocarriers therapeutic effect focus type nanocarriers according mikhailian two type question focus asking point denoted explicitly e.g. word research problem question research problem vernier effect related expectedanswertype eat implicit answer inferred information provided question e.g. answer type person eat question author sosa ontology methodology modified approach moldovan combining question type e.g. etc. corresponding class orkg schema e.g. paper problem etc. question pattern define expected answer boolean what-who what-when which-where which-what who-what instance question author recent paper insect pattern who-what also classified question according following dimension orkg-content classification based structure orkg schema paper-based question content single multiple research paper e.g. paper use dblp dataset comparison-based question content comparison i.e. property contribution participating comparison share e.g. common knowledge representation method semantic representation scholarly communication question content following approach mikhailian classify question either factoid i.e. non-factoid i.e. eat factoid question assume explicit mapping entity orkg ontology answer question requires inference sequence fact counting filtering consider question non-factoid classify according superlative e.g. common lead compound anuran antimicrobial peptide activity mechanism different biological membrane negation question e.g. percentage comparison lack class link question count e.g. total number specie examined invasion biology-enemy release hypothesis ranking question i.e. asking min/max value e.g. maximum female percentage brief psychotherapy depression study temporal question e.g. many study published combination various type content e.g. popular approach summarization finally characterized question based important property respective sparql query number triple pattern contrast simple question sparql query complex question consists single triple pattern presented table dataset contains simple complex question triple pattern table overview sciqa handcrafted query full size table table overview sciqa autogenerated query full size table query shape identified shape single edge chain star cycle tree etc query according bonifati note classification based number triple pattern incorporated classification simple question classified single-edge query query component noted keywords operator used build query instance select ask describe count regex str filter component give insight complicated query feature system support generate structured query exemple question query key part sciqa benchmark natural language question translated formal query sparql query language classified along comprehensive query classification presented method section first give overview sciqa query presenting three exemplary question corresponding query detail table provides statistic sciqa handcrafted query table provides statistic sciqa autogenerated query published full sciqa dataset corresponding snapshot orkg data zenodo present three example handcrafted question two example autogenerated question corresponding sparql query different research field although orkg alphanumeric identifier similar wikidata present query human-readable identifier property obtained corresponding resource label convenience sciqa accompanied sparql query preprocessor convert human-readable query back one alphanumeric identifier handcrafted question average energy generation energy source considered 5-year interval greenhouse gas reduction scenario germany first question sciqa-handcrafted belongs research field energy system domain mechanical engineering non-factoid question based comparison greenhouse gas reduction scenario germany summarizes result various study analyzing future low-carbon energy system focus electricity generation germany question average value energy generation different energy source 5-year interval typical research field consulted domain expert confirmed average value needed trend analysis example corresponding sparql query includes seven triple pattern eight query component shaped tree handcrafted question common knowledge representation method semantic representation scholarly communication second question sciqa-handcrafted belongs research field databases/information system domain computer science non-factoid question based orkg comparison semantic representation scholarly communication comparison provides overview publication semantic representation scholarly communication focusing scholarly communication whole specific data citation question typical one frequent occurrence information specifically commonly used knowledge representation data model scientific communication case resource description framework rdf http sparql query includes three triple pattern seven query component shaped chain handcrafted question study maximal geographic scale take place genetic variability coi variation study large sampled sequence third question sciqa-handcrafted belongs research field ecology biodiversity animal ecosystem organismic interaction domain zoology non-factoid question based comparison genetic variability coi variation study large sampled sequence compare genetic variability study containing cytochrome oxidase coi barcoding sequence question aim identify study maximum geographic scope took place case study conducted united state america mexico canada sparql query six triple pattern six query component shaped like tree autogenerated question provide highest benchmark result including metric score sequential mnist dataset fourth question sciqa-autogenerated belongs research field computer science non-factoid question based content orkg imported papers-with-code question fetching top best evaluation score recorded orkg result fetched distinct evaluation metric used evaluation related sparql query includes ten triple pattern nine query component shape tree autogenerated question list title research paper contain benchmark sst-2 binary classification dataset fifth question sciqa-autogenerated belongs research field computer science factoid question based content orkg imported papers-with-code describes evaluation result machine learning model benchmarked commonly used datasets natural language processing machine learning community question request title paper model benchmarked particular dataset case sst-2 binary classification dataset related sparql query includes six triple pattern four query component shape tree applicability feasibility evaluation section present two preliminary evaluation using handcrafted part sciqa benchmark first show result proof-of-concept implementation system based jarvisqa system second show initial insight using chatgpt answering handcrafted question proof-of-concept based jarvisqa preliminary analysis aim understand sciqa used system focused scholarly knowledge purpose investigate performance proof-of-concept implementation based jarvisqa experimental setup jarvisqa fundamentally designed answer question scholarly knowledge system based bert work table tabular view scholarly knowledge graph orkg comparison sciqa doe rely table tabular view comparison broader spectrum question/answer type reason answer handcrafted question jarvisqa correspond input form configured proof-of-concept implementation jarvisqa run compatible question sciqa use seven distinct experimental setup jarvisqa provides due limited coverage question system answer limit result two category question evaluation conducted term precision recall metric result table show evaluation result experiment two main category question normal overall category normal refers single-answer question category overall aggregate single-answer question question type jarvisqa answer listing boolean question note performance decrease across setup overall category complex nature sciqa benchmark answer expects unlike jarvisqa trained thus answer table evaluation result running jarvisqa handcrafted question sciqa benchmark jarvisqa setup follow similar notation introduced top performing setup indicated bold second best underlined full size table chatgpt sciqa besides use sciqa system focused scholarly knowledge performed additional preliminary evaluation based handcrafted question using chatgpt numerous llm adept solving common natural language task released chatgpt galactica lamda codex sparrow show better performance technical knowledge task e.g. galactica medical domain e.g. pubmedqa medmcqa etc experiment aim test llm sciqa estimate baseline performance llm scholarly question various topic chose chatgpt experiment one prominent llm moment domain-specific chatgpt able answer question sciqa source text paper topic question used develop dataset mostly openly available internet reason assume question sciqa potentially processed answered llm chatgpt way evaluation aim gain initial insight well one current famous llm trained specifically orkg data able answer complex query scholarly knowledge superlative comparison etc. experimental setup underlying model chatgpt designed generate detailed answer user question reason added additional prompt short handcrafted question get shorter answer similar answer sciqa although chatgpt response shorter still detailed future refined individual tuning prompt necessary obtain answer similar format answer dataset however decided way retrieving answer sufficient preliminary evaluation sciqa collecting answer question assessment correctness performed expert opinion four expert compared chatgpt answer answer sciqa dataset correct fact mentioned text returned chatgpt answer assessed correct otherwise result assessed incorrect also system returned response could answer question assessed answer answer independently assessed expert expert compared result discussed disagreement meeting discussion situation arose expert could agree whether answer derived paper data source mentioned question whether answer generated common sense general knowledge result expert assessed answer uncertain. table show four example four assessment type correct incorrect uncertain answer example include question sciqa sciqa answer answer chatgpt expert assessment answer chatgpt explanation result table provide overview result expert assessment found analysis chatgpt able generate answer handcrafted question fourteen answer correct answer incorrect nine answer uncertain although result slightly better compared result best performing configuration proof-of-concept implementation jarvisqa jarvis_ xls2 correct answer performance chatgpt answering question scientific knowledge still low correct answer preliminary evaluation show limited applicability low accuracy even current cutting-edge llm chatgpt answering specific question scholarly knowledge table result four expert assessment chatgpt answer handcrafted question sciqa benchmark full size table discussion section discus three key aspect sciqa higher complexity scholarly knowledge insufficiency llm dealing scholarly knowledge advancement knowledge graph towards cognitive knowledge graph facilitating integration semantic machine learning approach argue scholarly knowledge complex common sense knowledge e.g. encyclopedic knowledge illustrated complexity example e.g. fig example semantic unit knowledge simple entity description entity organization place person described set rdf triple statement entity identifier common subject contrast scholarly knowledge graph orkg scholarly contribution description comprises numerous interwoven entity description include example description process process step material characteristic component measurement simulation well bibliographic metadata single semantic unit orkg commonly consists dozen tightly interlinked entity description together reasonably convey information compared encyclopedic common sense knowledge often already single entity description contains sufficient information inherently complex structure scholarly knowledge graph make question answering significantly challenging demonstrated applicability feasibility evaluation particular result two preliminary evaluation show challenging system llm answer question scholarly knowledge neither system intended scholarly knowledge even trained orkg data llm chatgpt able perform well answering handcrafted question sciqa case system unable adequately solve challenge scholarly table table sample chatgpt answer evaluation result part qualitative assessment handcrafted sciqa benchmark full size table preliminary evaluation observed even system specifically designed academic data including one advanced llm available time article struggle excel sciqa benchmark sciqa dataset encompasses various question type stemming distinct entity within knowledge graph rather solely relying tabular view primary format jarvisqa operates moreover accurately respond sciqa query system must comprehend context question embedded orkg graph structure one contributing factor challenge deficiency nlp component tailored academic data entity linkers query builder another significant limitation llm like chatgpt bert posse contextual understanding specific knowledge graph orkg hinders performance sciqa benchmark taking account factor mentioned becomes increasingly clear pressing need research community rally behind sciqa benchmark collaborating develop system perform well sciqa researcher contribute improve expand dataset well make progress field scholarly knowledge goal mind launched scholarly question answering linked data qald challenge task using sciqa one open competition 22nd international semantic web conference challenge hope generate baseline inspire community create array scholarly-oriented tool system ultimately collaborative effort foster significant advancement field benefiting academia whole reason challenge even llm lie fact model good recreating common sense knowledge found varying form several different source however due nature employing probability distribution sequence word good dealing knowledge found single source issue also shown recently failed llm galactica trained scientific literature taken offline three day became clear model ratio hallucination reasonable answer unfortunate use deem inherent characteristic llm also addressed improvement model however combination llm symbolic knowledge representation approach orkg sciqa promising avenue leveraging potential also domain unique knowledge production science scholarly knowledge graph orkg demonstrate advance knowledge graph concept towards cognitive knowledge graph enable trustworthy integration artificial human intelligence cognitive knowledge graph constituent complex element idea theory approach claim conveyed example scholarly contribution also area industrial product model common vulnerability exposure description developer security omics data personalized medicine see base constituent cognitive knowledge graph complex fabric entity description arranged according certain pattern graphlets network analysis graph theory notion graphlet motif introduced provide structuring element whole graph individual node edge hence order able effectively represent manage complex knowledge artifact notion graphlets applied knowledge graph sciqa research contribution cognitive knowledge graph particular importance support step correlation causalityâ€”while correlation arises detection statistical relationship pattern data plan use rich contextual knowledge knowledge graph additional signal causality testing integration symbolic sub-symbolic intelligence hybridai breit recent survey approach help systematically anchor transparency traceability explainability trustworthiness reliability data science method conclusion future work section draw conclusion point direction future work address problem missing benchmark scholarly knowledge far system corresponding benchmark mainly geared towards encyclopedic knowledge composed relatively simple moderate semantic structure contrast consideration scientific knowledge combined knowledge graph rather new challenging due heterogeneous representation concept drift evolution time different level granularity novel semantic structure reason developed sciqa benchmark scholarly knowledge new challenging task next-generation system different researcher using defined bottom-up methodology sciqa contains handcrafted natural language question paraphrase corresponding human- machine-readable sparql query result question query analyzed according several classification cover different fine-grained research field computer science engineering chemistry geology immunology economics see table addition handcrafted question-answer pair semi-automatically created set question derived eight question template approach currently limited computer science domain large set homogeneously structured described data however orkg comprises homogeneously structured contribution description sciqa approach easily expanded research field initial result evaluation sciqa using jarvisqa chatgpt demonstrate difficulty scholarly knowledge general system designed answer question scholarly knowledge large language model capable advanced reasoning language understanding based insight conclude sciqa benchmark represents challenging task system implementation realistic feasible work foundation longer research technology development agenda envision advancing concept knowledge graph rather simple atomic entity description towards richer structured knowledge graph comprising fabric complex knowledge structure knowledge graph cell plan update sciqa annually orkg evolves include content question query answer also currently launch scholarly question answering linked data qald challenge task using sciqa one open competition 22nd international semantic web conference extension work perform federated scholarly knowledge graph link orkg content metadata article datasets people organization etc published scholarly infrastructure given advanced standardization persistent identification description interlinking exchange metadata entity well provision programmatic access metadata system graphql-based pid graph federated integration orkg content metadata contextual entity straightforward enable scholarly knowledge understood broadly include scientific knowledge published article interlinked contextual knowledge production consumption