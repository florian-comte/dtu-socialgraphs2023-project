introduction representation analysis motion human body research subject constantly expanding increasing use sensor time series analysis smoothing fundamental step real world application especially sensor involved certain amount noise captured presence noise lead unstable result even wrong conclusion data analyzed classification clustering algorithm applied paper data registered motion sensor called metamotionr mmr mbientlab analysed sensor measure spatial orientation hip store quaternion time series motion hip joint registered two different condition natural walking walking made difficult knee immobilizer orthosis simulate walking impairment due amyotrophic lateral sclerosis multiple sclerosis neurodegenerative disease context different smoothing technique quaternion time series reviewed smoothing technique proposed selected simplicity implementation power making available technique developed euclidean space basis method new technique proposed compared previous one real artificially noisy data understand influence level noise affect performance smoothing method rest paper organized follows quaternion time series smoothing method section review literature related smoothing quaternion time series introduces proposal description difference approach section theoretical comparison method presented experimental result section show experimental setting result quaternion wavelet smoothing real noisy data term classification performance real application data human behaviour study section application proposed method real dataset related human behaviour study described conclusion idea research summarized conclusion section quaternion time series smoothing method interested smoothing method suitable one-dimensional quaternion-valued signal let f\in l^2 signal quaternion space introduction quaternion quaternion time series described section supplementary material existing smoothing method type signal generalization classical smoothing technique originally introduced euclidean space fourier transform spline function wavelet method adapted quaternion time series different way spline function often used quaternion algebra interpolate signal example application spline directly applied smoothing signal regarding quaternion wavelet transform qwt extensive review found naïve approach smooth component quaternion independently described well known literature different isomorphism space characterized specific property deployed smoothing precisely application wavelet method quaternion time series described clifford wavelet clifford multiresolution analysis introduced application quaternion time series possible isomorphic clifford algebra 0,2 author limited consideration theoretical statement method definition haar wavelet idea mitrea explored context image analysis haar wavelet applied biomedical data tomography image written term quaternion compressed via wavelet idea matrix-valued wavelet mvws explored ginzberg walden demonstrating wavelet defined previous literature trivial new matrix-valued wavelet using isomorphism space matrix 4x4 quaternion-structure condition coefficient proposed isomorphism defined aligned q=w+x bmatrix -z\\ -x\\ bmatrix aligned adopting quaternion-structured mvws hence quaternion wavelet designed matlab code compute wavelet filter coefficient presented code perform wavelet analysis quaternion signal provided application mvws simulated quaternion time series described fletcher extended work adding new wavelet filter different length explained arrange filter matrix analysing image applying analysis colour vector image different approach analysing quaternion signal presented multi-resolution technique based second generation wavelet transform quaternion lifting scheme defined follows input data set split two disjoint set even odd indexed sample sample odd index predicted based sample even index using slerp squad method quaternion time series detail section supplementary material next input value odd index replaced offset difference value prediction output updated coarse-scale coefficient average value input sample step necessary stability wavelet transform procedure wavelet function used reconstructed necessary computation another approach quaternion signal smoothing wavelet described resorting method explored application fourier transform quaternion signal analysis focused unit quaternion time series element time series object space unit quaternion i.e space unit norm quaternion underlying idea unit quaternion time series smooth change angular velocity small rationale smoothing process applied angular velocity space angular velocity three-dimensional euclidean space real wavelet technique even general smoothing technique euclidean space deployed smoothing process unit quaternion time series reconstructed order obtain angular velocity without employing derivative following approximation formula used given unit quaternion time series q_1 q_n\ time step measured angular velocity approximated follows see definition quaternion logarithm aligned _i=\frac log q_i^ i+1 i=1 n-1 aligned approximate angular velocity ... _n\ quaternion time series reconstructed see definition quaternion exponential aligned q_i =q_1 j=2 i=1 n-1 aligned following idea proposed approach considers logarithm transformation _1\ tangent space ^3\ logarithm unit quaternion time series time series 3-dimensional euclidean space defined follows aligned =\left aligned idea employ suitable smoothing process component logarithm quaternion compute unit quaternion taking quaternionic exponential follows aligned =\exp aligned component logarithm always note logarithm defined sufficiently small neighbourhood zero exponential indeed globally defined bijective sufficiently small neighbourhood zero hip motion small amplitude issue affect application logarithm transformation smoother respect angular velocity intrinsic difference explored description difference approach section difference definition transformed space smoothing performed affect performance classification task way described experimental result section description difference approach firstly interested comparison image two transformation involved quaternionic logarithm function unit quaternion ^3\ =\frac ^3\ write vector unit norm ^3\ direction w/|q| consequence image ball radius ^3\ given unit quaternion time series q_1 q_n\ angular velocity approximated equation _i=\frac log q_i^ i+1 q_i^ i+1 _1\ therefore consideration applied numerator image ball radius ^3\ theoretical framework angular velocity calculated derivative limit image transformation ^3\ since application angular velocity approximated small positive constant image transformation ball ^3\ radius larger logarithm transformation develop comparison consider geometric interpretation transformation involved angular velocity logarithm logarithm function applied unit quaternion give point corresponding tangent space identity quaternion take logarithm quaternion time series obtain series lying entirely one specific tangent space angular velocity transformation log q_i^ i+1 give point tangent space q_i\ corresponding i+1 consequence corresponding time series ^3\ collection point lying tangent space different point another critical issue must taken account space _1\ unit quaternion product commutative well known formula =\exp p+q doe hold general commute case cambell-baker-hausdorff formula product two non-commuting exponential applied general case provides infinite correction term within right-hand side exponential problem exactly solved rotational data note isomorph _1\ exact formula determine value quaternion =\exp stated experimental result section describe different smoothing method transformation affect classification table reporting detailed result commented classification result section found section 1.2 supplementary material data description original data set consists unit quaternion time series observation time step data recorded wearable motion sensor called metamotionr mmr inertial measurement unit imu mbientlab device combine three-axis accelerometer gyroscope magnetometer determine orientation form unit quaternion worn level hip measure angle rotation hip walking movement frequency signal captured motion sensor periodic composed actual walking step referred gait cycle gait cycle defined sequence movement performed body phase delimited two successive contact given foot ground therefore compute average gait cycle referred individual gait pattern jointly aligning time pointwise averaging segmented gait cycle data related healthy subject collected two different condition first evaluation made letting subject perform natural walking movement another record made using knee immobilizer orthosis simulate walking impairment represent rotation choose unit quaternion representation convenience suggested literature rotation analysis unit quaternion represents rotation given object frame coordinate system imu coordinate system fixed coordinate system defined reference choose first orientation observed individual gait pattern igp reference unit quaternion igp represents rotation first orientation one observed given time reason original dataset first element time series quaternion representing identity rotation also processed data order straighten igp first last element igp identity rotation order apply wavelet method original time series re-sampled time point figure component-wise representation individual gait pattern data full size image figure depicts component-wise representation individual gait pattern data color represents two condition data collected used classification task natural walk hindered walk alternative representation provided section supplementary material order understand influence noise performance different smoothing method applied method described method experimental setting section data different level noise added generated noisy data set adding gaussian noise logarithm curve original data set quaternion time series transformed ^3\ logarithm transformation gaussian noise added independently component consider observation corresponds -th subject correspond -th component multidimensional time series identifies median line gaussian error term aligned =m_k +\epsilon cov i=1 i=k aligned cov generated exponential-like covariance function two parameter aligned =\alpha -\beta aligned different degree type noise simulated varying parameter =0.001\ =0.01\ low noise moderately correlated =0.01\ =0.001\ moderate noise highly correlated =0.01\ =0.01\ moderate noise moderately correlated =0.01\ =0.1\ moderate noise weakly correlated =0.1\ =0.01\ high noise moderately correlated datasets obtained visually represented section 1.1 supplementary material method experimental setting wavelet smoothing method fourier spline smoothing one embedded one two transformation _1\ ^3\ compared order smooth signal using wavelet discrete wavelet transform applied soft thresholding generalized sense multidimensional signal aligned array t_p 1-\frac t_p t_p array aligned -dimensional vector detail coefficient dwt chosen threshold universal threshold generalized t_p=\sigma 3\log standard deviation noise since generally unknown practical situation must estimated following idea described median absolute deviation mad detail coefficient proposed mad =median estimated standard deviation multidimensional case aligned =\frac mad 0.6745 aligned d_1 ^i\ vector detail coefficient obtained first level decomposition component function pooled together following mother wavelet decomposition level considered mother wavelet haar daubechies daubechies daubechies daubechies d16 least asymmetric la8 least asymmetric la16 least asymmetric la20 best localized bl14 best localized bl20 decomposition level fourier smoothing performed non-parametric regression smoothing using basis element covariates roughness penalty used linear cubic quintic spline employed cross validated parameter curve number knot considered parameter selected optimal optimization outside scope paper combination parameter smoothing process evaluated term classification performance -nearest neighbour -nn model used perform classification original smoothed quaternion time series select smoothing method remove noise preserving important feature distinguish two group -nn algorithm non-parametric classification method firstly developed observation classified plurality vote neighbour object assigned class common among nearest neighbour positive integer typically small set standard value value generally optimized based data hand outside scope paper distance-based algorithm easily generalized quaternion time series using dynamic time warping dtw distance detail dtw see section supplementary material result presented present paper based cross validation exercise fold defined obtain stable result working small sample size series test fold distance series training fold computed nearest time series training set considered majority label assigned tested series result evaluated term accuracy expressed term percentage correct classified observation coupled auc area roc curve accuracy measure computed fold summarized term averaged value increase robustness conclusion linear regression model studied model influence transformation choice smoothing method performance index level noise described data description section simulated ten time original data simulated adding minimal noise setting =0.0001\ =0.0001\ accuracy auc evaluated considered target variable smoothing method type transformation considered covariates computation performed using software core team figure generated ggplot2 package v3.3.3 wickham plotly package plotly technology inc. collaborative data science montréal 2015. http function developed work provided github repository classification result performance reached -nn original individual gait pattern data set accuracy 0.8200 auc 0.9149 applying smoothing process data logarithm transformation method choice parameter accuracy 0.8100 almost auc 0.8531 small difference combination parameter considering angular velocity transformation performance lower original data logarithm smoothing process show smoothing process doe improve classification performance curve considered already nearly smooth instead case performance lower seems suggest smoothing process remove important feature data already exploitable comparison angular velocity method logarithm show smooth function involved logarithm better preserve characteristic curve fig explanation result could logarithm transformation smoother angular velocity present higher variability also regular curve figure result original data performance different method evaluated term accuracy auc shape distinguishes fourier spline wavelet smoothing method colour distinguish logarithm angular velocity transformation full size image figure result obtained classification using noisy datasets fixed value autocorrelation =0.01\ increasing value variance parameter =0.001\ =0.01\ =0.1\ full size image classification result noisy data analysis variance fixed autocorrelation consider performance reached noisy data set defined data description start fixed value autocorrelation =0.01\ increasing value variance parameter =0.001\ =0.01\ =0.1\ consider first data set generated =0.001\ =0.01\ introducing low level noise noise low variance moderate correlation nearest point performance reached without smoothing accuracy 0.550 auc 0.601 best method identified wavelet smoothing method different combination parameter wavelet term accuracy accuracy 0.5433 auc 0.6527 wavelet decomposition level term auc accuracy 0.49 auc 0.6958 angular velocity method achieves poorer result term classification accuracy smoothing function choice parameter accuracy 0.47 fig highest value auc reached wavelet d16 decomposition level accuracy 0.3933 auc 0.7434 note almost smoothing method transformation yield higher auc lower accuracy method competitive non-smoothed data set best logarithm transformation consider data set moderate noise variance moderate correlation =0.01\ =0.01\ data classification without smoothing obtains accuracy 0.407 auc 0.608 case logarithm transformation performs similarly angular velocity difficult identify best method fig almost smoothing method obtain better result non-smoothed data set consider noisy data set generated high noise variance moderate correlation close point =0.1 =0.01 data classification without smoothing reach accuracy 0.5 auc 0.609 one method reach better result original data classification term auc accuracy wavelet la20 decomposition level accuracy=0.5 auc=0.6322 higher value auc reached lower level accuracy reason difficult identify best method logarithm transformation seems obtain better result term auc doe use angular velocity similar value accuracy see fig figure result obtained classification using noisy datasets generated fixed value variance =0.01\ varying value autocorrelation parameter =0.001\ =0.01\ =0.1\ full size image classification result noisy data analysis autocorrelation fixed variance consider performance reached noisy data set generated fixed value variance =0.01\ varying value autocorrelation parameter =0.001\ =0.01\ =0.1\ considering data set moderate noise variance =0.01\ high correlation close point =0.001\ obtain data classification without smoothing reach accuracy 0.630 auc 0.591 data set angular velocity performs better logarithm term auc worse term accuracy transformation method obtain worse performance raw data classification smoothing suggested fig general confirm noise level low smoothing process necessary increase risk removing important feature data set consider data set moderate noise variance moderate correlation =0.01\ =0.01\ seen data classification without smoothing obtains accuracy 0.407 auc 0.608 almost smoothing method obtain better result non-smoothed data set fig consider noisy data generated moderate noise variance low correlation close point =0.01\ =0.1\ data classification without smoothing reach accuracy 0.640 auc 0.678 lot smoothing method reach better result original data classification consider smoothing transformation angular velocity transformation seems lower result best result term accuracy reached wavelet decomposition level accuracy=0.7200 auc=0.7136 term auc best method wavelet la8 decomposition level accuracy=0.6467 auc=0.7416 see fig final result influence noise clear curve nearly smooth smoothing method improve classification whereas introduce noise term high variance low autocorrelation need applying smoothing method becomes clear performance improved process see fig figure method fourier spline wavelet transformation logarithm angular velocity best result presented best result identified using sum accuracy auc shape distinguishes fourier spline wavelet method colour distinguish logarithm angular velocity transformation full size image order confirm validity proposed method linear regression analysis accuracy auc performed influence transformation function smoothing method evaluated ten data set generated combination parameter defined original data set simulated parameter =\beta =0.0001\ covariates three model variable transformation indicates transformation function angular velocity logarithm factor variable reference value angular velocity two level variable smoothing_method indicates smoothing method fourier spline wavelet factor variable reference value fourier three level par alpha par beta correspond noise parameter defined numerical variable target variable three model accuracy auc logit transformation applied target variable transform range 0,1 -\infty +\infty produce larger range value common transformation target variable still satisfy normality assumption common transformation solve problem bootstrap procedure applied obtain coefficient confidence interval result regarding model accuracy outcome summarized table result auc similar accuracy one shown section 1.3 supplementary material anova table linear model also presented section 1.3 supplementary material table linear regression model accuracy target variable bootstrap procedure full size table smoothing method wavelet spline fourier seem global impact quality smoothing process term classification performance coefficient wavelet spline method compared reference level fourier significant instead coefficient related logarithm transformation respect angular velocity transformation significantly different zero positive result confirm positive effect logarithm transformation target variable also observe variance autocorrelation parameter noise generation significant negative coefficient higher level noise negative impact classification performance expected real application data human behaviour study order confirm potential proposed method section report empirical evidence achieved highly noised dataset data considered related behavioural study small free-standing conversational group sample dataset called congreg8 available following link http described dataset contains full-body motion data collected free-standing conversational group three human newcomer approach group intention joining figure component-wise representation quaternion time series abdominal orientation blue line represent subject group behaviour ignorance red line represent subject group behaviour welcome full size image quaternion time series collected body marker skeleton digitally reconstructed different bone tracked term position orientation last set time series selected abdominal orientation considering could one better summarize capture personal attitude people small group respect newcomer also sample one subject group control correlation subject computational time different length time series cut standard length correspond temporal span 8.5 second target variable related behaviour group annotated author welcome ignore preliminary selection dataset containing quaternion time series related subject labeled ignore welcome obtained final dataset shown fig alternative representation provided section supplementary material time series extremely noised visual inspection discriminatory power clear figure depicts result obtained adapting pipeline described experimental result section figure result real data evaluated term accuracy auc shape distinguishes fourier spline wavelet smoothing method colour distinguish logarithm angular velocity transformation full size image performance different smoothing method evaluated term classification performance measured accuracy auc fig shape distinguishes fourier spline wavelet smoothing method colour distinguish logarithm angular velocity transformation classification data without application smoothing method obtain accuracy 0.6 auc 0.665 observe accuracy slightly improved fourier logarithm method fourier angular velocity wavelet angular velocity improvement doe correspond improvement auc lower original dataset classification one best method cubic quintic spline logarithm transformation obtain best result term auc accuracy 0.6 original classification could improved varying threshold classification set 0.5 default also observe application different wavelet introduce variability result wavelet applied logarithm method reach performance data without smoothing angular velocity method show better result term accuracy much worse term auc confirm conclusion simulation study regression method best smoothing method seems data specific logarithm transformation lead general better result angular velocity one basis empirical evidence achieved real data better performance reached term auc investigation threshold selection required observe improvement also term accuracy lead improve research study threshold selection affect performance conclusion paper present new method smooth unit quaternion time series new method manages unit quaternion proper way transforming time series euclidean space take advantage existing smoothing technique compare wavelet method respect fourier spline smoothing method result evaluated term classification performance data set unit quaternion time series describing walking cycle binary outcome variable five version data set created adding noise original data evaluate influence different degree noise smoothing process result original data set noisy one confirm need applying smoothing technique data noisy opportuneness deploying proposed method namely using logarithm transformation unit quaternion time series obtain general better result instead obtained evidence one different smoothing technique ^3\ used seems depend particular data set analyzed evaluated case case basis application proposed method real noisy dataset confirms conclusion simulated study avenue research include application different noise model evaluate influence particular nature data set application classification model deeper analysis classical smoothing method applied context furthermore quaternion representation visualization method explored depth approach described paper exploited term functional representation quaternion time series aspect need study function developed work provided github repository